{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** I used the same architecture as recommended in the documentation that was used in the \"Show and Tell\" paper: In the encoder part, resnet 50 is used followed by linear layer and batch normalization. In the decoder part, a single layer LSTM is used followed by linear layer. For selecting the parameters, I consulted \"Show and Tell\" (ST) & \"Show, Attend, and Tell\" (SAT) paper. As in ST paper, embedding size of 512 is used, and in SAT paper, batch size of 64 is used. For vocabulary, threhsold of 5 is used as was used in the ST paper for SBU data description and Karapathy's \"Deep Visual Alignment\" paper.\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** I sticked to the provided default transform values for the captioning task since it already had the crop operation (224 dimension) and normalization operation as required for the pre-trained ResNet. The random horizontal flipping operation helps with the logical augmentation that can be used in the training process.  \n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** Linear Embedding layer in the CNN and all the parameters of decoder are trained. Since, we are using pre-trained ResNet there is no requirement to retrain them.\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** For optimization used the go-to optimizer algorithm of vision community - Adam. Adam combines the benefit of both RMSprop and Adagrad, and has been widely adopted in the community to tackle different problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 326/414113 [00:00<02:06, 3258.60it/s]\u001b[A\n",
      "  0%|          | 752/414113 [00:00<01:57, 3505.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.90s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 1193/414113 [00:00<01:50, 3734.84it/s]\u001b[A\n",
      "  0%|          | 1627/414113 [00:00<01:45, 3895.53it/s]\u001b[A\n",
      "  0%|          | 2048/414113 [00:00<01:43, 3983.58it/s]\u001b[A\n",
      "  1%|          | 2460/414113 [00:00<01:42, 4022.11it/s]\u001b[A\n",
      "  1%|          | 2884/414113 [00:00<01:40, 4082.76it/s]\u001b[A\n",
      "  1%|          | 3289/414113 [00:00<01:40, 4071.50it/s]\u001b[A\n",
      "  1%|          | 3727/414113 [00:00<01:38, 4158.82it/s]\u001b[A\n",
      "  1%|          | 4155/414113 [00:01<01:37, 4193.63it/s]\u001b[A\n",
      "  1%|          | 4579/414113 [00:01<01:37, 4205.83it/s]\u001b[A\n",
      "  1%|          | 5015/414113 [00:01<01:36, 4248.82it/s]\u001b[A\n",
      "  1%|▏         | 5442/414113 [00:01<01:36, 4254.08it/s]\u001b[A\n",
      "  1%|▏         | 5871/414113 [00:01<01:35, 4263.65it/s]\u001b[A\n",
      "  2%|▏         | 6297/414113 [00:01<01:35, 4261.86it/s]\u001b[A\n",
      "  2%|▏         | 6739/414113 [00:01<01:34, 4307.52it/s]\u001b[A\n",
      "  2%|▏         | 7169/414113 [00:01<01:34, 4301.88it/s]\u001b[A\n",
      "  2%|▏         | 7599/414113 [00:01<01:34, 4283.56it/s]\u001b[A\n",
      "  2%|▏         | 8036/414113 [00:01<01:34, 4306.77it/s]\u001b[A\n",
      "  2%|▏         | 8479/414113 [00:02<01:33, 4340.63it/s]\u001b[A\n",
      "  2%|▏         | 8916/414113 [00:02<01:33, 4348.87it/s]\u001b[A\n",
      "  2%|▏         | 9351/414113 [00:02<01:33, 4325.67it/s]\u001b[A\n",
      "  2%|▏         | 9784/414113 [00:02<01:33, 4305.09it/s]\u001b[A\n",
      "  2%|▏         | 10215/414113 [00:02<01:35, 4233.59it/s]\u001b[A\n",
      "  3%|▎         | 10639/414113 [00:02<01:35, 4235.42it/s]\u001b[A\n",
      "  3%|▎         | 11063/414113 [00:02<01:35, 4222.17it/s]\u001b[A\n",
      "  3%|▎         | 11498/414113 [00:02<01:34, 4258.64it/s]\u001b[A\n",
      "  3%|▎         | 11925/414113 [00:02<01:34, 4262.01it/s]\u001b[A\n",
      "  3%|▎         | 12352/414113 [00:02<01:35, 4224.21it/s]\u001b[A\n",
      "  3%|▎         | 12775/414113 [00:03<01:35, 4190.05it/s]\u001b[A\n",
      "  3%|▎         | 13214/414113 [00:03<01:34, 4247.75it/s]\u001b[A\n",
      "  3%|▎         | 13640/414113 [00:03<01:34, 4246.45it/s]\u001b[A\n",
      "  3%|▎         | 14078/414113 [00:03<01:33, 4284.82it/s]\u001b[A\n",
      "  4%|▎         | 14507/414113 [00:03<01:33, 4271.13it/s]\u001b[A\n",
      "  4%|▎         | 14942/414113 [00:03<01:32, 4294.40it/s]\u001b[A\n",
      "  4%|▎         | 15375/414113 [00:03<01:32, 4302.27it/s]\u001b[A\n",
      "  4%|▍         | 15824/414113 [00:03<01:31, 4356.10it/s]\u001b[A\n",
      "  4%|▍         | 16260/414113 [00:03<01:33, 4271.50it/s]\u001b[A\n",
      "  4%|▍         | 16697/414113 [00:03<01:32, 4297.22it/s]\u001b[A\n",
      "  4%|▍         | 17128/414113 [00:04<01:32, 4272.55it/s]\u001b[A\n",
      "  4%|▍         | 17570/414113 [00:04<01:31, 4313.65it/s]\u001b[A\n",
      "  4%|▍         | 18018/414113 [00:04<01:30, 4361.40it/s]\u001b[A\n",
      "  4%|▍         | 18468/414113 [00:04<01:29, 4401.89it/s]\u001b[A\n",
      "  5%|▍         | 18909/414113 [00:04<01:30, 4367.40it/s]\u001b[A\n",
      "  5%|▍         | 19347/414113 [00:04<01:30, 4365.98it/s]\u001b[A\n",
      "  5%|▍         | 19784/414113 [00:04<01:30, 4362.49it/s]\u001b[A\n",
      "  5%|▍         | 20228/414113 [00:04<01:29, 4383.70it/s]\u001b[A\n",
      "  5%|▍         | 20667/414113 [00:04<01:30, 4354.89it/s]\u001b[A\n",
      "  5%|▌         | 21103/414113 [00:04<01:30, 4355.14it/s]\u001b[A\n",
      "  5%|▌         | 21539/414113 [00:05<01:30, 4344.14it/s]\u001b[A\n",
      "  5%|▌         | 21974/414113 [00:05<01:34, 4140.88it/s]\u001b[A\n",
      "  5%|▌         | 22414/414113 [00:05<01:32, 4213.10it/s]\u001b[A\n",
      "  6%|▌         | 22863/414113 [00:05<01:31, 4291.55it/s]\u001b[A\n",
      "  6%|▌         | 23299/414113 [00:05<01:30, 4311.08it/s]\u001b[A\n",
      "  6%|▌         | 23732/414113 [00:05<01:30, 4309.97it/s]\u001b[A\n",
      "  6%|▌         | 24164/414113 [00:05<01:32, 4216.25it/s]\u001b[A\n",
      "  6%|▌         | 24587/414113 [00:05<01:33, 4159.75it/s]\u001b[A\n",
      "  6%|▌         | 25015/414113 [00:05<01:32, 4194.70it/s]\u001b[A\n",
      "  6%|▌         | 25472/414113 [00:05<01:30, 4299.20it/s]\u001b[A\n",
      "  6%|▋         | 25916/414113 [00:06<01:29, 4339.70it/s]\u001b[A\n",
      "  6%|▋         | 26351/414113 [00:06<01:30, 4283.48it/s]\u001b[A\n",
      "  6%|▋         | 26789/414113 [00:06<01:29, 4310.00it/s]\u001b[A\n",
      "  7%|▋         | 27222/414113 [00:06<01:29, 4313.85it/s]\u001b[A\n",
      "  7%|▋         | 27658/414113 [00:06<01:29, 4327.29it/s]\u001b[A\n",
      "  7%|▋         | 28107/414113 [00:06<01:28, 4373.86it/s]\u001b[A\n",
      "  7%|▋         | 28545/414113 [00:06<01:28, 4371.90it/s]\u001b[A\n",
      "  7%|▋         | 28983/414113 [00:06<01:28, 4365.99it/s]\u001b[A\n",
      "  7%|▋         | 29420/414113 [00:06<01:28, 4344.95it/s]\u001b[A\n",
      "  7%|▋         | 29877/414113 [00:06<01:27, 4409.86it/s]\u001b[A\n",
      "  7%|▋         | 30319/414113 [00:07<01:28, 4353.45it/s]\u001b[A\n",
      "  7%|▋         | 30764/414113 [00:07<01:27, 4380.00it/s]\u001b[A\n",
      "  8%|▊         | 31211/414113 [00:07<01:26, 4404.75it/s]\u001b[A\n",
      "  8%|▊         | 31652/414113 [00:07<01:27, 4394.72it/s]\u001b[A\n",
      "  8%|▊         | 32095/414113 [00:07<01:26, 4403.84it/s]\u001b[A\n",
      "  8%|▊         | 32536/414113 [00:07<01:27, 4370.65it/s]\u001b[A\n",
      "  8%|▊         | 32974/414113 [00:07<01:28, 4302.83it/s]\u001b[A\n",
      "  8%|▊         | 33405/414113 [00:07<01:28, 4286.01it/s]\u001b[A\n",
      "  8%|▊         | 33844/414113 [00:07<01:28, 4314.73it/s]\u001b[A\n",
      "  8%|▊         | 34276/414113 [00:07<01:28, 4315.29it/s]\u001b[A\n",
      "  8%|▊         | 34708/414113 [00:08<01:28, 4296.36it/s]\u001b[A\n",
      "  8%|▊         | 35138/414113 [00:08<01:28, 4264.77it/s]\u001b[A\n",
      "  9%|▊         | 35565/414113 [00:08<01:29, 4237.83it/s]\u001b[A\n",
      "  9%|▊         | 35989/414113 [00:08<01:29, 4211.53it/s]\u001b[A\n",
      "  9%|▉         | 36411/414113 [00:08<01:31, 4106.57it/s]\u001b[A\n",
      "  9%|▉         | 36865/414113 [00:08<01:29, 4226.24it/s]\u001b[A\n",
      "  9%|▉         | 37306/414113 [00:08<01:28, 4277.67it/s]\u001b[A\n",
      "  9%|▉         | 37735/414113 [00:08<01:28, 4270.92it/s]\u001b[A\n",
      "  9%|▉         | 38163/414113 [00:08<01:28, 4253.17it/s]\u001b[A\n",
      "  9%|▉         | 38610/414113 [00:09<01:27, 4314.36it/s]\u001b[A\n",
      "  9%|▉         | 39043/414113 [00:09<01:27, 4310.08it/s]\u001b[A\n",
      " 10%|▉         | 39488/414113 [00:09<01:26, 4349.44it/s]\u001b[A\n",
      " 10%|▉         | 39924/414113 [00:09<01:26, 4337.55it/s]\u001b[A\n",
      " 10%|▉         | 40359/414113 [00:09<01:26, 4298.70it/s]\u001b[A\n",
      " 10%|▉         | 40790/414113 [00:09<01:27, 4288.41it/s]\u001b[A\n",
      " 10%|▉         | 41220/414113 [00:09<01:27, 4252.54it/s]\u001b[A\n",
      " 10%|█         | 41646/414113 [00:09<01:27, 4249.86it/s]\u001b[A\n",
      " 10%|█         | 42075/414113 [00:09<01:27, 4259.43it/s]\u001b[A\n",
      " 10%|█         | 42504/414113 [00:09<01:27, 4267.73it/s]\u001b[A\n",
      " 10%|█         | 42931/414113 [00:10<01:27, 4258.36it/s]\u001b[A\n",
      " 10%|█         | 43358/414113 [00:10<01:27, 4260.33it/s]\u001b[A\n",
      " 11%|█         | 43794/414113 [00:10<01:26, 4289.65it/s]\u001b[A\n",
      " 11%|█         | 44224/414113 [00:10<01:26, 4261.83it/s]\u001b[A\n",
      " 11%|█         | 44651/414113 [00:10<01:27, 4213.15it/s]\u001b[A\n",
      " 11%|█         | 45093/414113 [00:10<01:26, 4271.23it/s]\u001b[A\n",
      " 11%|█         | 45528/414113 [00:10<01:25, 4291.97it/s]\u001b[A\n",
      " 11%|█         | 45958/414113 [00:10<01:26, 4280.25it/s]\u001b[A\n",
      " 11%|█         | 46387/414113 [00:10<01:25, 4281.15it/s]\u001b[A\n",
      " 11%|█▏        | 46816/414113 [00:10<01:26, 4265.66it/s]\u001b[A\n",
      " 11%|█▏        | 47243/414113 [00:11<01:26, 4265.56it/s]\u001b[A\n",
      " 12%|█▏        | 47670/414113 [00:11<01:26, 4235.93it/s]\u001b[A\n",
      " 12%|█▏        | 48116/414113 [00:11<01:25, 4297.08it/s]\u001b[A\n",
      " 12%|█▏        | 48546/414113 [00:11<01:25, 4257.32it/s]\u001b[A\n",
      " 12%|█▏        | 48973/414113 [00:11<01:26, 4235.16it/s]\u001b[A\n",
      " 12%|█▏        | 49404/414113 [00:11<01:25, 4256.91it/s]\u001b[A\n",
      " 12%|█▏        | 49836/414113 [00:11<01:25, 4274.33it/s]\u001b[A\n",
      " 12%|█▏        | 50286/414113 [00:11<01:23, 4337.74it/s]\u001b[A\n",
      " 12%|█▏        | 50731/414113 [00:11<01:23, 4369.51it/s]\u001b[A\n",
      " 12%|█▏        | 51169/414113 [00:11<01:23, 4323.17it/s]\u001b[A\n",
      " 12%|█▏        | 51609/414113 [00:12<01:23, 4343.04it/s]\u001b[A\n",
      " 13%|█▎        | 52044/414113 [00:12<01:23, 4315.70it/s]\u001b[A\n",
      " 13%|█▎        | 52501/414113 [00:12<01:22, 4386.70it/s]\u001b[A\n",
      " 13%|█▎        | 52942/414113 [00:12<01:22, 4393.06it/s]\u001b[A\n",
      " 13%|█▎        | 53382/414113 [00:12<01:22, 4346.97it/s]\u001b[A\n",
      " 13%|█▎        | 53818/414113 [00:12<01:24, 4270.80it/s]\u001b[A\n",
      " 13%|█▎        | 54246/414113 [00:12<01:24, 4244.84it/s]\u001b[A\n",
      " 13%|█▎        | 54700/414113 [00:12<01:23, 4327.18it/s]\u001b[A\n",
      " 13%|█▎        | 55135/414113 [00:12<01:22, 4333.41it/s]\u001b[A\n",
      " 13%|█▎        | 55572/414113 [00:12<01:22, 4344.02it/s]\u001b[A\n",
      " 14%|█▎        | 56014/414113 [00:13<01:22, 4366.36it/s]\u001b[A\n",
      " 14%|█▎        | 56451/414113 [00:13<01:22, 4355.48it/s]\u001b[A\n",
      " 14%|█▎        | 56887/414113 [00:13<01:22, 4349.37it/s]\u001b[A\n",
      " 14%|█▍        | 57343/414113 [00:13<01:20, 4408.36it/s]\u001b[A\n",
      " 14%|█▍        | 57785/414113 [00:13<01:21, 4357.01it/s]\u001b[A\n",
      " 14%|█▍        | 58222/414113 [00:13<01:22, 4325.20it/s]\u001b[A\n",
      " 14%|█▍        | 58655/414113 [00:13<02:39, 2235.06it/s]\u001b[A\n",
      " 14%|█▍        | 59091/414113 [00:14<02:15, 2617.70it/s]\u001b[A\n",
      " 14%|█▍        | 59516/414113 [00:14<01:59, 2958.39it/s]\u001b[A\n",
      " 14%|█▍        | 59960/414113 [00:14<01:47, 3286.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 60379/414113 [00:14<01:40, 3512.86it/s]\u001b[A\n",
      " 15%|█▍        | 60814/414113 [00:14<01:34, 3725.89it/s]\u001b[A\n",
      " 15%|█▍        | 61255/414113 [00:14<01:30, 3905.95it/s]\u001b[A\n",
      " 15%|█▍        | 61678/414113 [00:14<01:28, 3985.86it/s]\u001b[A\n",
      " 15%|█▍        | 62109/414113 [00:14<01:26, 4076.14it/s]\u001b[A\n",
      " 15%|█▌        | 62533/414113 [00:14<01:25, 4112.60it/s]\u001b[A\n",
      " 15%|█▌        | 62956/414113 [00:14<01:24, 4139.24it/s]\u001b[A\n",
      " 15%|█▌        | 63391/414113 [00:15<01:23, 4199.52it/s]\u001b[A\n",
      " 15%|█▌        | 63831/414113 [00:15<01:22, 4257.63it/s]\u001b[A\n",
      " 16%|█▌        | 64267/414113 [00:15<01:21, 4286.14it/s]\u001b[A\n",
      " 16%|█▌        | 64704/414113 [00:15<01:21, 4308.05it/s]\u001b[A\n",
      " 16%|█▌        | 65147/414113 [00:15<01:20, 4342.65it/s]\u001b[A\n",
      " 16%|█▌        | 65583/414113 [00:15<01:20, 4319.09it/s]\u001b[A\n",
      " 16%|█▌        | 66019/414113 [00:15<01:20, 4330.85it/s]\u001b[A\n",
      " 16%|█▌        | 66453/414113 [00:15<01:20, 4315.31it/s]\u001b[A\n",
      " 16%|█▌        | 66886/414113 [00:15<01:21, 4284.01it/s]\u001b[A\n",
      " 16%|█▋        | 67315/414113 [00:15<01:21, 4237.99it/s]\u001b[A\n",
      " 16%|█▋        | 67747/414113 [00:16<01:21, 4261.29it/s]\u001b[A\n",
      " 16%|█▋        | 68183/414113 [00:16<01:20, 4289.17it/s]\u001b[A\n",
      " 17%|█▋        | 68616/414113 [00:16<01:20, 4298.98it/s]\u001b[A\n",
      " 17%|█▋        | 69047/414113 [00:16<01:20, 4278.67it/s]\u001b[A\n",
      " 17%|█▋        | 69476/414113 [00:16<01:22, 4200.31it/s]\u001b[A\n",
      " 17%|█▋        | 69906/414113 [00:16<01:21, 4228.69it/s]\u001b[A\n",
      " 17%|█▋        | 70344/414113 [00:16<01:20, 4271.95it/s]\u001b[A\n",
      " 17%|█▋        | 70772/414113 [00:16<01:21, 4221.06it/s]\u001b[A\n",
      " 17%|█▋        | 71212/414113 [00:16<01:20, 4271.97it/s]\u001b[A\n",
      " 17%|█▋        | 71644/414113 [00:17<01:19, 4283.57it/s]\u001b[A\n",
      " 17%|█▋        | 72073/414113 [00:17<01:20, 4261.64it/s]\u001b[A\n",
      " 18%|█▊        | 72501/414113 [00:17<01:20, 4265.42it/s]\u001b[A\n",
      " 18%|█▊        | 72940/414113 [00:17<01:19, 4300.60it/s]\u001b[A\n",
      " 18%|█▊        | 73383/414113 [00:17<01:18, 4338.59it/s]\u001b[A\n",
      " 18%|█▊        | 73818/414113 [00:17<01:19, 4297.04it/s]\u001b[A\n",
      " 18%|█▊        | 74248/414113 [00:17<01:19, 4291.51it/s]\u001b[A\n",
      " 18%|█▊        | 74678/414113 [00:17<01:19, 4270.65it/s]\u001b[A\n",
      " 18%|█▊        | 75106/414113 [00:17<01:19, 4268.15it/s]\u001b[A\n",
      " 18%|█▊        | 75535/414113 [00:17<01:19, 4272.24it/s]\u001b[A\n",
      " 18%|█▊        | 75969/414113 [00:18<01:18, 4290.48it/s]\u001b[A\n",
      " 18%|█▊        | 76399/414113 [00:18<01:18, 4281.20it/s]\u001b[A\n",
      " 19%|█▊        | 76831/414113 [00:18<01:18, 4290.10it/s]\u001b[A\n",
      " 19%|█▊        | 77261/414113 [00:18<01:18, 4288.50it/s]\u001b[A\n",
      " 19%|█▉        | 77690/414113 [00:18<01:20, 4173.61it/s]\u001b[A\n",
      " 19%|█▉        | 78121/414113 [00:18<01:19, 4212.08it/s]\u001b[A\n",
      " 19%|█▉        | 78554/414113 [00:18<01:19, 4245.93it/s]\u001b[A\n",
      " 19%|█▉        | 78988/414113 [00:18<01:18, 4271.04it/s]\u001b[A\n",
      " 19%|█▉        | 79416/414113 [00:18<01:19, 4214.80it/s]\u001b[A\n",
      " 19%|█▉        | 79865/414113 [00:18<01:17, 4291.61it/s]\u001b[A\n",
      " 19%|█▉        | 80295/414113 [00:19<01:18, 4243.94it/s]\u001b[A\n",
      " 19%|█▉        | 80727/414113 [00:19<01:18, 4262.57it/s]\u001b[A\n",
      " 20%|█▉        | 81157/414113 [00:19<01:17, 4272.60it/s]\u001b[A\n",
      " 20%|█▉        | 81585/414113 [00:19<01:20, 4153.76it/s]\u001b[A\n",
      " 20%|█▉        | 82014/414113 [00:19<01:19, 4193.68it/s]\u001b[A\n",
      " 20%|█▉        | 82459/414113 [00:19<01:17, 4266.48it/s]\u001b[A\n",
      " 20%|██        | 82887/414113 [00:19<01:17, 4264.79it/s]\u001b[A\n",
      " 20%|██        | 83315/414113 [00:19<01:19, 4143.77it/s]\u001b[A\n",
      " 20%|██        | 83731/414113 [00:19<01:24, 3909.17it/s]\u001b[A\n",
      " 20%|██        | 84165/414113 [00:19<01:21, 4028.87it/s]\u001b[A\n",
      " 20%|██        | 84593/414113 [00:20<01:20, 4098.74it/s]\u001b[A\n",
      " 21%|██        | 85021/414113 [00:20<01:19, 4148.64it/s]\u001b[A\n",
      " 21%|██        | 85463/414113 [00:20<01:17, 4224.62it/s]\u001b[A\n",
      " 21%|██        | 85901/414113 [00:20<01:16, 4268.20it/s]\u001b[A\n",
      " 21%|██        | 86336/414113 [00:20<01:16, 4292.25it/s]\u001b[A\n",
      " 21%|██        | 86778/414113 [00:20<01:15, 4328.39it/s]\u001b[A\n",
      " 21%|██        | 87212/414113 [00:20<01:15, 4329.61it/s]\u001b[A\n",
      " 21%|██        | 87654/414113 [00:20<01:14, 4355.69it/s]\u001b[A\n",
      " 21%|██▏       | 88098/414113 [00:20<01:14, 4379.66it/s]\u001b[A\n",
      " 21%|██▏       | 88554/414113 [00:20<01:13, 4431.27it/s]\u001b[A\n",
      " 21%|██▏       | 88998/414113 [00:21<01:14, 4369.33it/s]\u001b[A\n",
      " 22%|██▏       | 89436/414113 [00:21<01:14, 4356.52it/s]\u001b[A\n",
      " 22%|██▏       | 89872/414113 [00:21<01:15, 4307.47it/s]\u001b[A\n",
      " 22%|██▏       | 90320/414113 [00:21<01:14, 4356.74it/s]\u001b[A\n",
      " 22%|██▏       | 90773/414113 [00:21<01:13, 4405.22it/s]\u001b[A\n",
      " 22%|██▏       | 91214/414113 [00:21<01:13, 4381.21it/s]\u001b[A\n",
      " 22%|██▏       | 91662/414113 [00:21<01:13, 4410.27it/s]\u001b[A\n",
      " 22%|██▏       | 92104/414113 [00:21<01:14, 4344.58it/s]\u001b[A\n",
      " 22%|██▏       | 92539/414113 [00:21<01:14, 4312.63it/s]\u001b[A\n",
      " 22%|██▏       | 92976/414113 [00:22<01:14, 4327.95it/s]\u001b[A\n",
      " 23%|██▎       | 93410/414113 [00:22<01:16, 4204.45it/s]\u001b[A\n",
      " 23%|██▎       | 93832/414113 [00:22<01:16, 4204.30it/s]\u001b[A\n",
      " 23%|██▎       | 94294/414113 [00:22<01:14, 4318.85it/s]\u001b[A\n",
      " 23%|██▎       | 94740/414113 [00:22<01:13, 4358.42it/s]\u001b[A\n",
      " 23%|██▎       | 95194/414113 [00:22<01:12, 4410.21it/s]\u001b[A\n",
      " 23%|██▎       | 95636/414113 [00:22<01:12, 4399.92it/s]\u001b[A\n",
      " 23%|██▎       | 96078/414113 [00:22<01:12, 4404.91it/s]\u001b[A\n",
      " 23%|██▎       | 96519/414113 [00:22<01:12, 4385.08it/s]\u001b[A\n",
      " 23%|██▎       | 96958/414113 [00:22<01:12, 4367.09it/s]\u001b[A\n",
      " 24%|██▎       | 97395/414113 [00:23<01:12, 4348.31it/s]\u001b[A\n",
      " 24%|██▎       | 97841/414113 [00:23<01:12, 4378.76it/s]\u001b[A\n",
      " 24%|██▎       | 98280/414113 [00:23<01:13, 4316.73it/s]\u001b[A\n",
      " 24%|██▍       | 98723/414113 [00:23<01:12, 4347.13it/s]\u001b[A\n",
      " 24%|██▍       | 99161/414113 [00:23<01:12, 4354.85it/s]\u001b[A\n",
      " 24%|██▍       | 99610/414113 [00:23<01:11, 4393.20it/s]\u001b[A\n",
      " 24%|██▍       | 100050/414113 [00:23<01:11, 4384.93it/s]\u001b[A\n",
      " 24%|██▍       | 100489/414113 [00:23<01:11, 4361.29it/s]\u001b[A\n",
      " 24%|██▍       | 100936/414113 [00:23<01:11, 4391.78it/s]\u001b[A\n",
      " 24%|██▍       | 101376/414113 [00:23<01:14, 4193.56it/s]\u001b[A\n",
      " 25%|██▍       | 101812/414113 [00:24<01:13, 4240.62it/s]\u001b[A\n",
      " 25%|██▍       | 102238/414113 [00:24<01:13, 4235.99it/s]\u001b[A\n",
      " 25%|██▍       | 102676/414113 [00:24<01:12, 4277.02it/s]\u001b[A\n",
      " 25%|██▍       | 103127/414113 [00:24<01:11, 4343.13it/s]\u001b[A\n",
      " 25%|██▌       | 103566/414113 [00:24<01:11, 4356.60it/s]\u001b[A\n",
      " 25%|██▌       | 104012/414113 [00:24<01:10, 4386.39it/s]\u001b[A\n",
      " 25%|██▌       | 104452/414113 [00:24<01:10, 4361.91it/s]\u001b[A\n",
      " 25%|██▌       | 104889/414113 [00:24<01:11, 4331.33it/s]\u001b[A\n",
      " 25%|██▌       | 105323/414113 [00:24<01:11, 4320.29it/s]\u001b[A\n",
      " 26%|██▌       | 105763/414113 [00:24<01:11, 4340.87it/s]\u001b[A\n",
      " 26%|██▌       | 106207/414113 [00:25<01:10, 4369.57it/s]\u001b[A\n",
      " 26%|██▌       | 106645/414113 [00:25<01:10, 4340.40it/s]\u001b[A\n",
      " 26%|██▌       | 107080/414113 [00:25<01:11, 4298.92it/s]\u001b[A\n",
      " 26%|██▌       | 107511/414113 [00:25<01:11, 4296.63it/s]\u001b[A\n",
      " 26%|██▌       | 107941/414113 [00:25<01:11, 4286.09it/s]\u001b[A\n",
      " 26%|██▌       | 108377/414113 [00:25<01:11, 4306.12it/s]\u001b[A\n",
      " 26%|██▋       | 108809/414113 [00:25<01:10, 4308.76it/s]\u001b[A\n",
      " 26%|██▋       | 109253/414113 [00:25<01:10, 4345.01it/s]\u001b[A\n",
      " 26%|██▋       | 109688/414113 [00:25<01:10, 4311.70it/s]\u001b[A\n",
      " 27%|██▋       | 110120/414113 [00:25<01:11, 4278.05it/s]\u001b[A\n",
      " 27%|██▋       | 110548/414113 [00:26<01:11, 4253.15it/s]\u001b[A\n",
      " 27%|██▋       | 110988/414113 [00:26<01:10, 4294.47it/s]\u001b[A\n",
      " 27%|██▋       | 111429/414113 [00:26<01:09, 4327.62it/s]\u001b[A\n",
      " 27%|██▋       | 111863/414113 [00:26<01:09, 4330.35it/s]\u001b[A\n",
      " 27%|██▋       | 112299/414113 [00:26<01:09, 4336.62it/s]\u001b[A\n",
      " 27%|██▋       | 112748/414113 [00:26<01:08, 4381.24it/s]\u001b[A\n",
      " 27%|██▋       | 113194/414113 [00:26<01:08, 4401.80it/s]\u001b[A\n",
      " 27%|██▋       | 113635/414113 [00:26<01:09, 4335.71it/s]\u001b[A\n",
      " 28%|██▊       | 114069/414113 [00:26<01:09, 4291.68it/s]\u001b[A\n",
      " 28%|██▊       | 114518/414113 [00:26<01:08, 4349.12it/s]\u001b[A\n",
      " 28%|██▊       | 114959/414113 [00:27<01:08, 4364.70it/s]\u001b[A\n",
      " 28%|██▊       | 115408/414113 [00:27<01:07, 4401.36it/s]\u001b[A\n",
      " 28%|██▊       | 115863/414113 [00:27<01:07, 4443.38it/s]\u001b[A\n",
      " 28%|██▊       | 116308/414113 [00:27<01:08, 4354.82it/s]\u001b[A\n",
      " 28%|██▊       | 116755/414113 [00:27<01:08, 4370.10it/s]\u001b[A\n",
      " 28%|██▊       | 117193/414113 [00:27<01:08, 4351.00it/s]\u001b[A\n",
      " 28%|██▊       | 117629/414113 [00:27<01:08, 4341.84it/s]\u001b[A\n",
      " 29%|██▊       | 118064/414113 [00:27<01:08, 4340.28it/s]\u001b[A\n",
      " 29%|██▊       | 118499/414113 [00:27<01:09, 4229.49it/s]\u001b[A\n",
      " 29%|██▊       | 118923/414113 [00:28<01:12, 4070.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 119359/414113 [00:28<01:10, 4152.08it/s]\u001b[A\n",
      " 29%|██▉       | 119800/414113 [00:28<01:09, 4224.29it/s]\u001b[A\n",
      " 29%|██▉       | 120232/414113 [00:28<01:09, 4250.31it/s]\u001b[A\n",
      " 29%|██▉       | 120682/414113 [00:28<01:07, 4321.13it/s]\u001b[A\n",
      " 29%|██▉       | 121130/414113 [00:28<01:07, 4367.19it/s]\u001b[A\n",
      " 29%|██▉       | 121568/414113 [00:28<01:08, 4270.58it/s]\u001b[A\n",
      " 29%|██▉       | 122006/414113 [00:28<01:07, 4302.77it/s]\u001b[A\n",
      " 30%|██▉       | 122438/414113 [00:28<01:08, 4281.54it/s]\u001b[A\n",
      " 30%|██▉       | 122882/414113 [00:28<01:07, 4326.08it/s]\u001b[A\n",
      " 30%|██▉       | 123316/414113 [00:29<01:08, 4268.90it/s]\u001b[A\n",
      " 30%|██▉       | 123771/414113 [00:29<01:06, 4348.23it/s]\u001b[A\n",
      " 30%|██▉       | 124211/414113 [00:29<01:06, 4360.94it/s]\u001b[A\n",
      " 30%|███       | 124648/414113 [00:29<01:07, 4315.16it/s]\u001b[A\n",
      " 30%|███       | 125082/414113 [00:29<01:06, 4319.53it/s]\u001b[A\n",
      " 30%|███       | 125515/414113 [00:29<01:08, 4205.50it/s]\u001b[A\n",
      " 30%|███       | 125948/414113 [00:29<01:07, 4240.63it/s]\u001b[A\n",
      " 31%|███       | 126387/414113 [00:29<01:07, 4283.71it/s]\u001b[A\n",
      " 31%|███       | 126827/414113 [00:29<01:06, 4315.64it/s]\u001b[A\n",
      " 31%|███       | 127261/414113 [00:29<01:06, 4321.15it/s]\u001b[A\n",
      " 31%|███       | 127698/414113 [00:30<01:06, 4335.22it/s]\u001b[A\n",
      " 31%|███       | 128139/414113 [00:30<01:05, 4356.70it/s]\u001b[A\n",
      " 31%|███       | 128576/414113 [00:30<01:05, 4358.32it/s]\u001b[A\n",
      " 31%|███       | 129013/414113 [00:30<01:05, 4359.64it/s]\u001b[A\n",
      " 31%|███▏      | 129460/414113 [00:30<01:04, 4389.50it/s]\u001b[A\n",
      " 31%|███▏      | 129900/414113 [00:30<01:04, 4374.62it/s]\u001b[A\n",
      " 31%|███▏      | 130338/414113 [00:30<01:04, 4375.01it/s]\u001b[A\n",
      " 32%|███▏      | 130776/414113 [00:30<01:05, 4342.41it/s]\u001b[A\n",
      " 32%|███▏      | 131211/414113 [00:30<01:05, 4311.62it/s]\u001b[A\n",
      " 32%|███▏      | 131650/414113 [00:30<01:05, 4333.70it/s]\u001b[A\n",
      " 32%|███▏      | 132084/414113 [00:31<01:05, 4283.11it/s]\u001b[A\n",
      " 32%|███▏      | 132514/414113 [00:31<01:05, 4286.64it/s]\u001b[A\n",
      " 32%|███▏      | 132946/414113 [00:31<01:05, 4293.23it/s]\u001b[A\n",
      " 32%|███▏      | 133380/414113 [00:31<01:05, 4306.46it/s]\u001b[A\n",
      " 32%|███▏      | 133812/414113 [00:31<01:05, 4308.99it/s]\u001b[A\n",
      " 32%|███▏      | 134243/414113 [00:31<01:05, 4263.25it/s]\u001b[A\n",
      " 33%|███▎      | 134670/414113 [00:31<01:05, 4261.04it/s]\u001b[A\n",
      " 33%|███▎      | 135097/414113 [00:31<01:06, 4166.17it/s]\u001b[A\n",
      " 33%|███▎      | 135515/414113 [00:31<01:08, 4075.72it/s]\u001b[A\n",
      " 33%|███▎      | 135956/414113 [00:31<01:06, 4170.20it/s]\u001b[A\n",
      " 33%|███▎      | 136375/414113 [00:32<01:06, 4175.88it/s]\u001b[A\n",
      " 33%|███▎      | 136807/414113 [00:32<01:05, 4215.89it/s]\u001b[A\n",
      " 33%|███▎      | 137237/414113 [00:32<01:05, 4240.68it/s]\u001b[A\n",
      " 33%|███▎      | 137676/414113 [00:32<01:04, 4284.40it/s]\u001b[A\n",
      " 33%|███▎      | 138129/414113 [00:32<01:03, 4354.93it/s]\u001b[A\n",
      " 33%|███▎      | 138566/414113 [00:32<01:03, 4340.84it/s]\u001b[A\n",
      " 34%|███▎      | 139001/414113 [00:32<01:03, 4341.58it/s]\u001b[A\n",
      " 34%|███▎      | 139451/414113 [00:32<01:02, 4386.24it/s]\u001b[A\n",
      " 34%|███▍      | 139890/414113 [00:32<01:02, 4382.41it/s]\u001b[A\n",
      " 34%|███▍      | 140329/414113 [00:32<01:03, 4318.09it/s]\u001b[A\n",
      " 34%|███▍      | 140762/414113 [00:33<01:09, 3929.64it/s]\u001b[A\n",
      " 34%|███▍      | 141183/414113 [00:33<01:08, 4007.38it/s]\u001b[A\n",
      " 34%|███▍      | 141602/414113 [00:33<01:07, 4059.29it/s]\u001b[A\n",
      " 34%|███▍      | 142027/414113 [00:33<01:06, 4114.34it/s]\u001b[A\n",
      " 34%|███▍      | 142465/414113 [00:33<01:04, 4190.51it/s]\u001b[A\n",
      " 35%|███▍      | 142912/414113 [00:33<01:03, 4268.33it/s]\u001b[A\n",
      " 35%|███▍      | 143353/414113 [00:33<01:02, 4308.59it/s]\u001b[A\n",
      " 35%|███▍      | 143791/414113 [00:33<01:02, 4329.11it/s]\u001b[A\n",
      " 35%|███▍      | 144239/414113 [00:33<01:01, 4371.29it/s]\u001b[A\n",
      " 35%|███▍      | 144693/414113 [00:34<01:00, 4418.28it/s]\u001b[A\n",
      " 35%|███▌      | 145136/414113 [00:34<01:01, 4363.93it/s]\u001b[A\n",
      " 35%|███▌      | 145574/414113 [00:34<01:01, 4349.71it/s]\u001b[A\n",
      " 35%|███▌      | 146019/414113 [00:34<01:01, 4377.59it/s]\u001b[A\n",
      " 35%|███▌      | 146462/414113 [00:34<01:00, 4391.15it/s]\u001b[A\n",
      " 35%|███▌      | 146902/414113 [00:34<01:00, 4385.73it/s]\u001b[A\n",
      " 36%|███▌      | 147341/414113 [00:34<01:05, 4055.68it/s]\u001b[A\n",
      " 36%|███▌      | 147768/414113 [00:34<01:04, 4115.92it/s]\u001b[A\n",
      " 36%|███▌      | 148184/414113 [00:34<01:05, 4035.42it/s]\u001b[A\n",
      " 36%|███▌      | 148629/414113 [00:34<01:03, 4150.27it/s]\u001b[A\n",
      " 36%|███▌      | 149077/414113 [00:35<01:02, 4242.87it/s]\u001b[A\n",
      " 36%|███▌      | 149508/414113 [00:35<01:02, 4261.38it/s]\u001b[A\n",
      " 36%|███▌      | 149936/414113 [00:35<01:02, 4215.54it/s]\u001b[A\n",
      " 36%|███▋      | 150359/414113 [00:35<01:02, 4199.68it/s]\u001b[A\n",
      " 36%|███▋      | 150808/414113 [00:35<01:01, 4280.28it/s]\u001b[A\n",
      " 37%|███▋      | 151238/414113 [00:35<01:01, 4265.54it/s]\u001b[A\n",
      " 37%|███▋      | 151680/414113 [00:35<01:00, 4310.53it/s]\u001b[A\n",
      " 37%|███▋      | 152121/414113 [00:35<01:00, 4336.48it/s]\u001b[A\n",
      " 37%|███▋      | 152561/414113 [00:35<01:00, 4354.78it/s]\u001b[A\n",
      " 37%|███▋      | 153013/414113 [00:35<00:59, 4402.71it/s]\u001b[A\n",
      " 37%|███▋      | 153461/414113 [00:36<00:58, 4424.81it/s]\u001b[A\n",
      " 37%|███▋      | 153904/414113 [00:36<00:58, 4414.55it/s]\u001b[A\n",
      " 37%|███▋      | 154346/414113 [00:36<00:58, 4407.22it/s]\u001b[A\n",
      " 37%|███▋      | 154788/414113 [00:36<00:58, 4408.72it/s]\u001b[A\n",
      " 37%|███▋      | 155229/414113 [00:36<00:59, 4374.07it/s]\u001b[A\n",
      " 38%|███▊      | 155667/414113 [00:36<00:59, 4369.64it/s]\u001b[A\n",
      " 38%|███▊      | 156105/414113 [00:36<00:59, 4355.12it/s]\u001b[A\n",
      " 38%|███▊      | 156541/414113 [00:36<00:59, 4346.64it/s]\u001b[A\n",
      " 38%|███▊      | 156976/414113 [00:36<00:59, 4301.84it/s]\u001b[A\n",
      " 38%|███▊      | 157407/414113 [00:36<00:59, 4279.74it/s]\u001b[A\n",
      " 38%|███▊      | 157836/414113 [00:37<00:59, 4278.26it/s]\u001b[A\n",
      " 38%|███▊      | 158284/414113 [00:37<00:59, 4334.89it/s]\u001b[A\n",
      " 38%|███▊      | 158725/414113 [00:37<00:58, 4355.24it/s]\u001b[A\n",
      " 38%|███▊      | 159174/414113 [00:37<00:58, 4394.22it/s]\u001b[A\n",
      " 39%|███▊      | 159614/414113 [00:37<00:58, 4345.21it/s]\u001b[A\n",
      " 39%|███▊      | 160063/414113 [00:37<00:57, 4386.81it/s]\u001b[A\n",
      " 39%|███▉      | 160505/414113 [00:37<00:57, 4394.75it/s]\u001b[A\n",
      " 39%|███▉      | 160953/414113 [00:37<00:57, 4416.93it/s]\u001b[A\n",
      " 39%|███▉      | 161412/414113 [00:37<00:56, 4466.46it/s]\u001b[A\n",
      " 39%|███▉      | 161859/414113 [00:37<00:57, 4361.47it/s]\u001b[A\n",
      " 39%|███▉      | 162299/414113 [00:38<00:57, 4372.41it/s]\u001b[A\n",
      " 39%|███▉      | 162737/414113 [00:38<00:58, 4326.98it/s]\u001b[A\n",
      " 39%|███▉      | 163171/414113 [00:38<00:58, 4285.27it/s]\u001b[A\n",
      " 40%|███▉      | 163602/414113 [00:38<00:58, 4290.80it/s]\u001b[A\n",
      " 40%|███▉      | 164032/414113 [00:38<01:00, 4166.76it/s]\u001b[A\n",
      " 40%|███▉      | 164477/414113 [00:38<00:58, 4247.36it/s]\u001b[A\n",
      " 40%|███▉      | 164903/414113 [00:38<00:58, 4229.34it/s]\u001b[A\n",
      " 40%|███▉      | 165327/414113 [00:38<01:00, 4129.53it/s]\u001b[A\n",
      " 40%|████      | 165755/414113 [00:38<00:59, 4171.06it/s]\u001b[A\n",
      " 40%|████      | 166173/414113 [00:39<00:59, 4160.13it/s]\u001b[A\n",
      " 40%|████      | 166603/414113 [00:39<00:58, 4200.59it/s]\u001b[A\n",
      " 40%|████      | 167024/414113 [00:39<00:59, 4174.94it/s]\u001b[A\n",
      " 40%|████      | 167442/414113 [00:39<01:00, 4070.24it/s]\u001b[A\n",
      " 41%|████      | 167893/414113 [00:39<00:58, 4190.45it/s]\u001b[A\n",
      " 41%|████      | 168314/414113 [00:39<00:59, 4119.43it/s]\u001b[A\n",
      " 41%|████      | 168728/414113 [00:39<00:59, 4098.38it/s]\u001b[A\n",
      " 41%|████      | 169161/414113 [00:39<00:58, 4165.01it/s]\u001b[A\n",
      " 41%|████      | 169601/414113 [00:39<00:57, 4231.09it/s]\u001b[A\n",
      " 41%|████      | 170026/414113 [00:39<00:58, 4178.90it/s]\u001b[A\n",
      " 41%|████      | 170455/414113 [00:40<00:57, 4211.55it/s]\u001b[A\n",
      " 41%|████▏     | 170877/414113 [00:40<00:59, 4060.73it/s]\u001b[A\n",
      " 41%|████▏     | 171292/414113 [00:40<00:59, 4087.00it/s]\u001b[A\n",
      " 41%|████▏     | 171738/414113 [00:40<00:57, 4190.97it/s]\u001b[A\n",
      " 42%|████▏     | 172159/414113 [00:40<00:58, 4147.25it/s]\u001b[A\n",
      " 42%|████▏     | 172588/414113 [00:40<00:57, 4188.79it/s]\u001b[A\n",
      " 42%|████▏     | 173008/414113 [00:40<00:58, 4095.89it/s]\u001b[A\n",
      " 42%|████▏     | 173425/414113 [00:40<00:58, 4115.49it/s]\u001b[A\n",
      " 42%|████▏     | 173851/414113 [00:40<00:57, 4155.56it/s]\u001b[A\n",
      " 42%|████▏     | 174283/414113 [00:40<00:57, 4201.96it/s]\u001b[A\n",
      " 42%|████▏     | 174710/414113 [00:41<00:56, 4219.39it/s]\u001b[A\n",
      " 42%|████▏     | 175133/414113 [00:41<00:57, 4143.96it/s]\u001b[A\n",
      " 42%|████▏     | 175561/414113 [00:41<00:57, 4181.23it/s]\u001b[A\n",
      " 42%|████▏     | 175980/414113 [00:41<01:48, 2204.23it/s]\u001b[A\n",
      " 43%|████▎     | 176414/414113 [00:41<01:31, 2585.45it/s]\u001b[A\n",
      " 43%|████▎     | 176854/414113 [00:41<01:20, 2949.58it/s]\u001b[A\n",
      " 43%|████▎     | 177286/414113 [00:41<01:12, 3259.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 177746/414113 [00:42<01:06, 3570.29it/s]\u001b[A\n",
      " 43%|████▎     | 178186/414113 [00:42<01:02, 3783.19it/s]\u001b[A\n",
      " 43%|████▎     | 178609/414113 [00:42<01:00, 3894.48it/s]\u001b[A\n",
      " 43%|████▎     | 179031/414113 [00:42<01:02, 3767.43it/s]\u001b[A\n",
      " 43%|████▎     | 179465/414113 [00:42<00:59, 3922.11it/s]\u001b[A\n",
      " 43%|████▎     | 179876/414113 [00:42<00:59, 3954.02it/s]\u001b[A\n",
      " 44%|████▎     | 180284/414113 [00:42<00:59, 3900.39it/s]\u001b[A\n",
      " 44%|████▎     | 180684/414113 [00:42<01:01, 3769.96it/s]\u001b[A\n",
      " 44%|████▎     | 181069/414113 [00:42<01:02, 3703.02it/s]\u001b[A\n",
      " 44%|████▍     | 181500/414113 [00:43<01:00, 3865.11it/s]\u001b[A\n",
      " 44%|████▍     | 181949/414113 [00:43<00:57, 4032.92it/s]\u001b[A\n",
      " 44%|████▍     | 182359/414113 [00:43<00:57, 4004.49it/s]\u001b[A\n",
      " 44%|████▍     | 182764/414113 [00:43<00:59, 3862.67it/s]\u001b[A\n",
      " 44%|████▍     | 183183/414113 [00:43<00:58, 3951.83it/s]\u001b[A\n",
      " 44%|████▍     | 183606/414113 [00:43<00:57, 4030.32it/s]\u001b[A\n",
      " 44%|████▍     | 184017/414113 [00:43<00:56, 4053.15it/s]\u001b[A\n",
      " 45%|████▍     | 184444/414113 [00:43<00:55, 4115.05it/s]\u001b[A\n",
      " 45%|████▍     | 184874/414113 [00:43<00:54, 4168.84it/s]\u001b[A\n",
      " 45%|████▍     | 185293/414113 [00:43<00:55, 4157.53it/s]\u001b[A\n",
      " 45%|████▍     | 185731/414113 [00:44<00:54, 4221.44it/s]\u001b[A\n",
      " 45%|████▍     | 186155/414113 [00:44<00:55, 4125.53it/s]\u001b[A\n",
      " 45%|████▌     | 186597/414113 [00:44<00:54, 4207.70it/s]\u001b[A\n",
      " 45%|████▌     | 187033/414113 [00:44<00:53, 4249.54it/s]\u001b[A\n",
      " 45%|████▌     | 187462/414113 [00:44<00:53, 4261.21it/s]\u001b[A\n",
      " 45%|████▌     | 187892/414113 [00:44<00:52, 4269.99it/s]\u001b[A\n",
      " 45%|████▌     | 188322/414113 [00:44<00:52, 4276.43it/s]\u001b[A\n",
      " 46%|████▌     | 188750/414113 [00:44<00:52, 4256.49it/s]\u001b[A\n",
      " 46%|████▌     | 189176/414113 [00:44<00:54, 4148.17it/s]\u001b[A\n",
      " 46%|████▌     | 189605/414113 [00:44<00:53, 4189.55it/s]\u001b[A\n",
      " 46%|████▌     | 190025/414113 [00:45<00:53, 4150.94it/s]\u001b[A\n",
      " 46%|████▌     | 190441/414113 [00:45<00:55, 4057.64it/s]\u001b[A\n",
      " 46%|████▌     | 190885/414113 [00:45<00:53, 4163.09it/s]\u001b[A\n",
      " 46%|████▌     | 191316/414113 [00:45<00:52, 4203.72it/s]\u001b[A\n",
      " 46%|████▋     | 191746/414113 [00:45<00:52, 4228.64it/s]\u001b[A\n",
      " 46%|████▋     | 192170/414113 [00:45<00:52, 4209.55it/s]\u001b[A\n",
      " 47%|████▋     | 192592/414113 [00:45<00:54, 4090.83it/s]\u001b[A\n",
      " 47%|████▋     | 193025/414113 [00:45<00:53, 4159.16it/s]\u001b[A\n",
      " 47%|████▋     | 193451/414113 [00:45<00:52, 4186.76it/s]\u001b[A\n",
      " 47%|████▋     | 193895/414113 [00:45<00:51, 4257.04it/s]\u001b[A\n",
      " 47%|████▋     | 194322/414113 [00:46<00:51, 4247.75it/s]\u001b[A\n",
      " 47%|████▋     | 194754/414113 [00:46<00:51, 4268.00it/s]\u001b[A\n",
      " 47%|████▋     | 195189/414113 [00:46<00:51, 4291.25it/s]\u001b[A\n",
      " 47%|████▋     | 195633/414113 [00:46<00:50, 4334.21it/s]\u001b[A\n",
      " 47%|████▋     | 196067/414113 [00:46<00:52, 4176.50it/s]\u001b[A\n",
      " 47%|████▋     | 196505/414113 [00:46<00:51, 4233.70it/s]\u001b[A\n",
      " 48%|████▊     | 196949/414113 [00:46<00:50, 4293.08it/s]\u001b[A\n",
      " 48%|████▊     | 197380/414113 [00:46<00:50, 4290.59it/s]\u001b[A\n",
      " 48%|████▊     | 197810/414113 [00:46<00:51, 4202.75it/s]\u001b[A\n",
      " 48%|████▊     | 198242/414113 [00:47<00:50, 4236.48it/s]\u001b[A\n",
      " 48%|████▊     | 198678/414113 [00:47<00:50, 4272.40it/s]\u001b[A\n",
      " 48%|████▊     | 199106/414113 [00:47<00:50, 4237.14it/s]\u001b[A\n",
      " 48%|████▊     | 199543/414113 [00:47<00:50, 4273.83it/s]\u001b[A\n",
      " 48%|████▊     | 199971/414113 [00:47<00:50, 4259.81it/s]\u001b[A\n",
      " 48%|████▊     | 200399/414113 [00:47<00:50, 4264.88it/s]\u001b[A\n",
      " 48%|████▊     | 200829/414113 [00:47<00:49, 4273.95it/s]\u001b[A\n",
      " 49%|████▊     | 201266/414113 [00:47<00:49, 4300.75it/s]\u001b[A\n",
      " 49%|████▊     | 201700/414113 [00:47<00:49, 4311.02it/s]\u001b[A\n",
      " 49%|████▉     | 202132/414113 [00:47<00:49, 4301.45it/s]\u001b[A\n",
      " 49%|████▉     | 202563/414113 [00:48<00:49, 4278.18it/s]\u001b[A\n",
      " 49%|████▉     | 203003/414113 [00:48<00:48, 4311.32it/s]\u001b[A\n",
      " 49%|████▉     | 203435/414113 [00:48<00:48, 4304.41it/s]\u001b[A\n",
      " 49%|████▉     | 203886/414113 [00:48<00:48, 4361.68it/s]\u001b[A\n",
      " 49%|████▉     | 204331/414113 [00:48<00:47, 4385.80it/s]\u001b[A\n",
      " 49%|████▉     | 204770/414113 [00:48<00:47, 4371.18it/s]\u001b[A\n",
      " 50%|████▉     | 205208/414113 [00:48<00:48, 4351.14it/s]\u001b[A\n",
      " 50%|████▉     | 205644/414113 [00:48<00:48, 4318.55it/s]\u001b[A\n",
      " 50%|████▉     | 206077/414113 [00:48<00:48, 4281.28it/s]\u001b[A\n",
      " 50%|████▉     | 206506/414113 [00:48<00:48, 4261.91it/s]\u001b[A\n",
      " 50%|████▉     | 206933/414113 [00:49<00:48, 4256.96it/s]\u001b[A\n",
      " 50%|█████     | 207375/414113 [00:49<00:48, 4304.45it/s]\u001b[A\n",
      " 50%|█████     | 207806/414113 [00:49<00:48, 4244.72it/s]\u001b[A\n",
      " 50%|█████     | 208231/414113 [00:49<00:48, 4222.18it/s]\u001b[A\n",
      " 50%|█████     | 208664/414113 [00:49<00:48, 4253.90it/s]\u001b[A\n",
      " 50%|█████     | 209090/414113 [00:49<00:48, 4236.22it/s]\u001b[A\n",
      " 51%|█████     | 209514/414113 [00:49<00:48, 4196.87it/s]\u001b[A\n",
      " 51%|█████     | 209942/414113 [00:49<00:48, 4220.08it/s]\u001b[A\n",
      " 51%|█████     | 210365/414113 [00:49<00:48, 4194.89it/s]\u001b[A\n",
      " 51%|█████     | 210785/414113 [00:49<00:49, 4137.54it/s]\u001b[A\n",
      " 51%|█████     | 211210/414113 [00:50<00:48, 4169.67it/s]\u001b[A\n",
      " 51%|█████     | 211647/414113 [00:50<00:47, 4226.30it/s]\u001b[A\n",
      " 51%|█████     | 212085/414113 [00:50<00:47, 4268.65it/s]\u001b[A\n",
      " 51%|█████▏    | 212513/414113 [00:50<00:47, 4200.09it/s]\u001b[A\n",
      " 51%|█████▏    | 212934/414113 [00:50<00:50, 3975.52it/s]\u001b[A\n",
      " 52%|█████▏    | 213377/414113 [00:50<00:48, 4098.97it/s]\u001b[A\n",
      " 52%|█████▏    | 213790/414113 [00:50<00:49, 4044.17it/s]\u001b[A\n",
      " 52%|█████▏    | 214236/414113 [00:50<00:48, 4158.84it/s]\u001b[A\n",
      " 52%|█████▏    | 214658/414113 [00:50<00:47, 4174.08it/s]\u001b[A\n",
      " 52%|█████▏    | 215086/414113 [00:50<00:47, 4202.54it/s]\u001b[A\n",
      " 52%|█████▏    | 215508/414113 [00:51<00:47, 4199.59it/s]\u001b[A\n",
      " 52%|█████▏    | 215929/414113 [00:51<00:47, 4150.79it/s]\u001b[A\n",
      " 52%|█████▏    | 216345/414113 [00:51<00:47, 4148.27it/s]\u001b[A\n",
      " 52%|█████▏    | 216769/414113 [00:51<00:47, 4173.02it/s]\u001b[A\n",
      " 52%|█████▏    | 217210/414113 [00:51<00:46, 4239.13it/s]\u001b[A\n",
      " 53%|█████▎    | 217650/414113 [00:51<00:45, 4283.64it/s]\u001b[A\n",
      " 53%|█████▎    | 218087/414113 [00:51<00:45, 4308.98it/s]\u001b[A\n",
      " 53%|█████▎    | 218529/414113 [00:51<00:45, 4339.37it/s]\u001b[A\n",
      " 53%|█████▎    | 218964/414113 [00:51<00:44, 4340.41it/s]\u001b[A\n",
      " 53%|█████▎    | 219422/414113 [00:51<00:44, 4408.28it/s]\u001b[A\n",
      " 53%|█████▎    | 219864/414113 [00:52<00:44, 4405.15it/s]\u001b[A\n",
      " 53%|█████▎    | 220305/414113 [00:52<00:45, 4269.86it/s]\u001b[A\n",
      " 53%|█████▎    | 220743/414113 [00:52<00:44, 4302.08it/s]\u001b[A\n",
      " 53%|█████▎    | 221175/414113 [00:52<00:44, 4292.65it/s]\u001b[A\n",
      " 54%|█████▎    | 221612/414113 [00:52<00:44, 4314.08it/s]\u001b[A\n",
      " 54%|█████▎    | 222044/414113 [00:52<00:44, 4270.44it/s]\u001b[A\n",
      " 54%|█████▎    | 222491/414113 [00:52<00:44, 4328.34it/s]\u001b[A\n",
      " 54%|█████▍    | 222927/414113 [00:52<00:44, 4334.70it/s]\u001b[A\n",
      " 54%|█████▍    | 223361/414113 [00:52<00:44, 4323.51it/s]\u001b[A\n",
      " 54%|█████▍    | 223795/414113 [00:53<00:43, 4326.20it/s]\u001b[A\n",
      " 54%|█████▍    | 224239/414113 [00:53<00:43, 4359.51it/s]\u001b[A\n",
      " 54%|█████▍    | 224676/414113 [00:53<00:43, 4339.55it/s]\u001b[A\n",
      " 54%|█████▍    | 225119/414113 [00:53<00:43, 4364.28it/s]\u001b[A\n",
      " 54%|█████▍    | 225556/414113 [00:53<00:43, 4355.57it/s]\u001b[A\n",
      " 55%|█████▍    | 225992/414113 [00:53<00:43, 4316.75it/s]\u001b[A\n",
      " 55%|█████▍    | 226427/414113 [00:53<00:43, 4324.60it/s]\u001b[A\n",
      " 55%|█████▍    | 226865/414113 [00:53<00:43, 4340.07it/s]\u001b[A\n",
      " 55%|█████▍    | 227300/414113 [00:53<00:43, 4341.52it/s]\u001b[A\n",
      " 55%|█████▍    | 227739/414113 [00:53<00:42, 4354.91it/s]\u001b[A\n",
      " 55%|█████▌    | 228179/414113 [00:54<00:42, 4365.93it/s]\u001b[A\n",
      " 55%|█████▌    | 228616/414113 [00:54<00:43, 4300.70it/s]\u001b[A\n",
      " 55%|█████▌    | 229051/414113 [00:54<00:42, 4314.53it/s]\u001b[A\n",
      " 55%|█████▌    | 229483/414113 [00:54<00:43, 4248.84it/s]\u001b[A\n",
      " 56%|█████▌    | 229909/414113 [00:54<00:43, 4241.34it/s]\u001b[A\n",
      " 56%|█████▌    | 230338/414113 [00:54<00:43, 4255.56it/s]\u001b[A\n",
      " 56%|█████▌    | 230778/414113 [00:54<00:42, 4297.39it/s]\u001b[A\n",
      " 56%|█████▌    | 231208/414113 [00:54<00:42, 4297.35it/s]\u001b[A\n",
      " 56%|█████▌    | 231638/414113 [00:54<00:42, 4291.00it/s]\u001b[A\n",
      " 56%|█████▌    | 232068/414113 [00:54<00:43, 4166.76it/s]\u001b[A\n",
      " 56%|█████▌    | 232489/414113 [00:55<00:43, 4177.80it/s]\u001b[A\n",
      " 56%|█████▌    | 232908/414113 [00:55<00:43, 4129.16it/s]\u001b[A\n",
      " 56%|█████▋    | 233363/414113 [00:55<00:42, 4246.48it/s]\u001b[A\n",
      " 56%|█████▋    | 233789/414113 [00:55<00:42, 4245.79it/s]\u001b[A\n",
      " 57%|█████▋    | 234215/414113 [00:55<00:42, 4247.37it/s]\u001b[A\n",
      " 57%|█████▋    | 234641/414113 [00:55<00:42, 4234.26it/s]\u001b[A\n",
      " 57%|█████▋    | 235065/414113 [00:55<00:42, 4210.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 235502/414113 [00:55<00:41, 4254.45it/s]\u001b[A\n",
      " 57%|█████▋    | 235928/414113 [00:55<00:42, 4203.04it/s]\u001b[A\n",
      " 57%|█████▋    | 236349/414113 [00:55<00:42, 4152.69it/s]\u001b[A\n",
      " 57%|█████▋    | 236767/414113 [00:56<00:42, 4158.54it/s]\u001b[A\n",
      " 57%|█████▋    | 237184/414113 [00:56<00:42, 4148.22it/s]\u001b[A\n",
      " 57%|█████▋    | 237602/414113 [00:56<00:42, 4155.17it/s]\u001b[A\n",
      " 57%|█████▋    | 238042/414113 [00:56<00:41, 4223.72it/s]\u001b[A\n",
      " 58%|█████▊    | 238465/414113 [00:56<00:42, 4174.04it/s]\u001b[A\n",
      " 58%|█████▊    | 238883/414113 [00:56<00:42, 4161.87it/s]\u001b[A\n",
      " 58%|█████▊    | 239324/414113 [00:56<00:41, 4230.90it/s]\u001b[A\n",
      " 58%|█████▊    | 239748/414113 [00:56<00:41, 4220.86it/s]\u001b[A\n",
      " 58%|█████▊    | 240185/414113 [00:56<00:40, 4259.82it/s]\u001b[A\n",
      " 58%|█████▊    | 240627/414113 [00:56<00:40, 4304.54it/s]\u001b[A\n",
      " 58%|█████▊    | 241062/414113 [00:57<00:40, 4317.72it/s]\u001b[A\n",
      " 58%|█████▊    | 241495/414113 [00:57<00:40, 4278.34it/s]\u001b[A\n",
      " 58%|█████▊    | 241934/414113 [00:57<00:39, 4309.81it/s]\u001b[A\n",
      " 59%|█████▊    | 242366/414113 [00:57<00:39, 4298.39it/s]\u001b[A\n",
      " 59%|█████▊    | 242816/414113 [00:57<00:39, 4356.32it/s]\u001b[A\n",
      " 59%|█████▊    | 243252/414113 [00:57<00:40, 4254.37it/s]\u001b[A\n",
      " 59%|█████▉    | 243679/414113 [00:57<00:40, 4229.16it/s]\u001b[A\n",
      " 59%|█████▉    | 244103/414113 [00:57<00:40, 4173.37it/s]\u001b[A\n",
      " 59%|█████▉    | 244521/414113 [00:57<00:40, 4165.33it/s]\u001b[A\n",
      " 59%|█████▉    | 244948/414113 [00:57<00:40, 4195.42it/s]\u001b[A\n",
      " 59%|█████▉    | 245378/414113 [00:58<00:39, 4224.27it/s]\u001b[A\n",
      " 59%|█████▉    | 245801/414113 [00:58<00:40, 4180.85it/s]\u001b[A\n",
      " 59%|█████▉    | 246220/414113 [00:58<00:40, 4166.41it/s]\u001b[A\n",
      " 60%|█████▉    | 246655/414113 [00:58<00:39, 4218.70it/s]\u001b[A\n",
      " 60%|█████▉    | 247098/414113 [00:58<00:39, 4279.42it/s]\u001b[A\n",
      " 60%|█████▉    | 247537/414113 [00:58<00:38, 4311.09it/s]\u001b[A\n",
      " 60%|█████▉    | 247984/414113 [00:58<00:38, 4355.70it/s]\u001b[A\n",
      " 60%|█████▉    | 248420/414113 [00:58<00:38, 4322.45it/s]\u001b[A\n",
      " 60%|██████    | 248853/414113 [00:58<00:38, 4291.63it/s]\u001b[A\n",
      " 60%|██████    | 249292/414113 [00:58<00:38, 4320.11it/s]\u001b[A\n",
      " 60%|██████    | 249725/414113 [00:59<00:38, 4321.76it/s]\u001b[A\n",
      " 60%|██████    | 250174/414113 [00:59<00:37, 4370.71it/s]\u001b[A\n",
      " 61%|██████    | 250612/414113 [00:59<00:37, 4342.87it/s]\u001b[A\n",
      " 61%|██████    | 251070/414113 [00:59<00:36, 4410.57it/s]\u001b[A\n",
      " 61%|██████    | 251516/414113 [00:59<00:36, 4424.24it/s]\u001b[A\n",
      " 61%|██████    | 251959/414113 [00:59<00:37, 4360.76it/s]\u001b[A\n",
      " 61%|██████    | 252400/414113 [00:59<00:36, 4374.14it/s]\u001b[A\n",
      " 61%|██████    | 252838/414113 [00:59<00:37, 4325.99it/s]\u001b[A\n",
      " 61%|██████    | 253271/414113 [00:59<00:37, 4315.42it/s]\u001b[A\n",
      " 61%|██████▏   | 253703/414113 [01:00<00:38, 4135.71it/s]\u001b[A\n",
      " 61%|██████▏   | 254141/414113 [01:00<00:38, 4204.06it/s]\u001b[A\n",
      " 61%|██████▏   | 254563/414113 [01:00<00:39, 4090.48it/s]\u001b[A\n",
      " 62%|██████▏   | 255004/414113 [01:00<00:38, 4179.53it/s]\u001b[A\n",
      " 62%|██████▏   | 255424/414113 [01:00<00:39, 4002.40it/s]\u001b[A\n",
      " 62%|██████▏   | 255858/414113 [01:00<00:38, 4096.38it/s]\u001b[A\n",
      " 62%|██████▏   | 256300/414113 [01:00<00:37, 4188.38it/s]\u001b[A\n",
      " 62%|██████▏   | 256730/414113 [01:00<00:37, 4220.21it/s]\u001b[A\n",
      " 62%|██████▏   | 257170/414113 [01:00<00:36, 4271.81it/s]\u001b[A\n",
      " 62%|██████▏   | 257599/414113 [01:00<00:37, 4228.64it/s]\u001b[A\n",
      " 62%|██████▏   | 258041/414113 [01:01<00:36, 4283.81it/s]\u001b[A\n",
      " 62%|██████▏   | 258481/414113 [01:01<00:36, 4316.54it/s]\u001b[A\n",
      " 63%|██████▎   | 258914/414113 [01:01<00:36, 4292.67it/s]\u001b[A\n",
      " 63%|██████▎   | 259356/414113 [01:01<00:35, 4328.34it/s]\u001b[A\n",
      " 63%|██████▎   | 259790/414113 [01:01<00:35, 4317.10it/s]\u001b[A\n",
      " 63%|██████▎   | 260223/414113 [01:01<00:35, 4287.92it/s]\u001b[A\n",
      " 63%|██████▎   | 260664/414113 [01:01<00:35, 4322.44it/s]\u001b[A\n",
      " 63%|██████▎   | 261103/414113 [01:01<00:35, 4341.64it/s]\u001b[A\n",
      " 63%|██████▎   | 261538/414113 [01:01<00:35, 4257.47it/s]\u001b[A\n",
      " 63%|██████▎   | 261965/414113 [01:01<00:36, 4136.64it/s]\u001b[A\n",
      " 63%|██████▎   | 262391/414113 [01:02<00:36, 4170.13it/s]\u001b[A\n",
      " 63%|██████▎   | 262837/414113 [01:02<00:35, 4250.58it/s]\u001b[A\n",
      " 64%|██████▎   | 263268/414113 [01:02<00:35, 4267.67it/s]\u001b[A\n",
      " 64%|██████▎   | 263713/414113 [01:02<00:34, 4318.15it/s]\u001b[A\n",
      " 64%|██████▍   | 264148/414113 [01:02<00:34, 4326.64it/s]\u001b[A\n",
      " 64%|██████▍   | 264582/414113 [01:02<00:34, 4319.01it/s]\u001b[A\n",
      " 64%|██████▍   | 265015/414113 [01:02<00:34, 4310.87it/s]\u001b[A\n",
      " 64%|██████▍   | 265460/414113 [01:02<00:34, 4349.52it/s]\u001b[A\n",
      " 64%|██████▍   | 265896/414113 [01:02<00:34, 4290.67it/s]\u001b[A\n",
      " 64%|██████▍   | 266331/414113 [01:02<00:34, 4307.98it/s]\u001b[A\n",
      " 64%|██████▍   | 266763/414113 [01:03<00:34, 4258.90it/s]\u001b[A\n",
      " 65%|██████▍   | 267206/414113 [01:03<00:34, 4307.77it/s]\u001b[A\n",
      " 65%|██████▍   | 267640/414113 [01:03<00:33, 4317.37it/s]\u001b[A\n",
      " 65%|██████▍   | 268094/414113 [01:03<00:33, 4379.78it/s]\u001b[A\n",
      " 65%|██████▍   | 268533/414113 [01:03<00:33, 4331.51it/s]\u001b[A\n",
      " 65%|██████▍   | 268991/414113 [01:03<00:32, 4401.64it/s]\u001b[A\n",
      " 65%|██████▌   | 269432/414113 [01:03<00:33, 4362.23it/s]\u001b[A\n",
      " 65%|██████▌   | 269869/414113 [01:03<00:33, 4293.32it/s]\u001b[A\n",
      " 65%|██████▌   | 270299/414113 [01:03<00:34, 4217.20it/s]\u001b[A\n",
      " 65%|██████▌   | 270750/414113 [01:04<00:33, 4299.37it/s]\u001b[A\n",
      " 65%|██████▌   | 271185/414113 [01:04<00:33, 4312.21it/s]\u001b[A\n",
      " 66%|██████▌   | 271624/414113 [01:04<00:32, 4332.86it/s]\u001b[A\n",
      " 66%|██████▌   | 272074/414113 [01:04<00:32, 4380.04it/s]\u001b[A\n",
      " 66%|██████▌   | 272513/414113 [01:04<00:33, 4251.79it/s]\u001b[A\n",
      " 66%|██████▌   | 272958/414113 [01:04<00:32, 4307.54it/s]\u001b[A\n",
      " 66%|██████▌   | 273399/414113 [01:04<00:32, 4336.40it/s]\u001b[A\n",
      " 66%|██████▌   | 273850/414113 [01:04<00:31, 4386.42it/s]\u001b[A\n",
      " 66%|██████▌   | 274290/414113 [01:04<00:32, 4346.69it/s]\u001b[A\n",
      " 66%|██████▋   | 274726/414113 [01:04<00:32, 4283.05it/s]\u001b[A\n",
      " 66%|██████▋   | 275161/414113 [01:05<00:32, 4300.99it/s]\u001b[A\n",
      " 67%|██████▋   | 275592/414113 [01:05<00:32, 4273.39it/s]\u001b[A\n",
      " 67%|██████▋   | 276040/414113 [01:05<00:31, 4331.31it/s]\u001b[A\n",
      " 67%|██████▋   | 276474/414113 [01:05<00:32, 4284.03it/s]\u001b[A\n",
      " 67%|██████▋   | 276903/414113 [01:05<00:32, 4262.33it/s]\u001b[A\n",
      " 67%|██████▋   | 277337/414113 [01:05<00:31, 4284.50it/s]\u001b[A\n",
      " 67%|██████▋   | 277766/414113 [01:05<00:32, 4260.66it/s]\u001b[A\n",
      " 67%|██████▋   | 278199/414113 [01:05<00:31, 4279.90it/s]\u001b[A\n",
      " 67%|██████▋   | 278628/414113 [01:05<00:31, 4248.97it/s]\u001b[A\n",
      " 67%|██████▋   | 279070/414113 [01:05<00:31, 4297.28it/s]\u001b[A\n",
      " 67%|██████▋   | 279500/414113 [01:06<00:31, 4243.37it/s]\u001b[A\n",
      " 68%|██████▊   | 279925/414113 [01:06<00:31, 4235.83it/s]\u001b[A\n",
      " 68%|██████▊   | 280353/414113 [01:06<00:31, 4246.12it/s]\u001b[A\n",
      " 68%|██████▊   | 280791/414113 [01:06<00:31, 4284.37it/s]\u001b[A\n",
      " 68%|██████▊   | 281220/414113 [01:06<00:31, 4228.06it/s]\u001b[A\n",
      " 68%|██████▊   | 281655/414113 [01:06<00:31, 4262.29it/s]\u001b[A\n",
      " 68%|██████▊   | 282095/414113 [01:06<00:30, 4300.58it/s]\u001b[A\n",
      " 68%|██████▊   | 282531/414113 [01:06<00:30, 4317.02it/s]\u001b[A\n",
      " 68%|██████▊   | 282963/414113 [01:06<00:30, 4256.87it/s]\u001b[A\n",
      " 68%|██████▊   | 283390/414113 [01:06<00:31, 4147.21it/s]\u001b[A\n",
      " 69%|██████▊   | 283833/414113 [01:07<00:30, 4227.63it/s]\u001b[A\n",
      " 69%|██████▊   | 284267/414113 [01:07<00:30, 4260.14it/s]\u001b[A\n",
      " 69%|██████▊   | 284698/414113 [01:07<00:30, 4272.96it/s]\u001b[A\n",
      " 69%|██████▉   | 285134/414113 [01:07<00:30, 4297.38it/s]\u001b[A\n",
      " 69%|██████▉   | 285566/414113 [01:07<00:29, 4302.96it/s]\u001b[A\n",
      " 69%|██████▉   | 286008/414113 [01:07<00:29, 4334.82it/s]\u001b[A\n",
      " 69%|██████▉   | 286443/414113 [01:07<00:29, 4338.14it/s]\u001b[A\n",
      " 69%|██████▉   | 286892/414113 [01:07<00:29, 4380.16it/s]\u001b[A\n",
      " 69%|██████▉   | 287331/414113 [01:07<00:28, 4372.33it/s]\u001b[A\n",
      " 69%|██████▉   | 287769/414113 [01:07<00:29, 4309.40it/s]\u001b[A\n",
      " 70%|██████▉   | 288201/414113 [01:08<00:29, 4304.25it/s]\u001b[A\n",
      " 70%|██████▉   | 288638/414113 [01:08<00:29, 4321.93it/s]\u001b[A\n",
      " 70%|██████▉   | 289072/414113 [01:08<00:28, 4325.28it/s]\u001b[A\n",
      " 70%|██████▉   | 289505/414113 [01:08<00:29, 4154.79it/s]\u001b[A\n",
      " 70%|███████   | 289934/414113 [01:08<00:29, 4192.75it/s]\u001b[A\n",
      " 70%|███████   | 290363/414113 [01:08<00:29, 4221.09it/s]\u001b[A\n",
      " 70%|███████   | 290817/414113 [01:08<00:28, 4311.90it/s]\u001b[A\n",
      " 70%|███████   | 291257/414113 [01:08<00:28, 4336.40it/s]\u001b[A\n",
      " 70%|███████   | 291692/414113 [01:08<00:28, 4289.56it/s]\u001b[A\n",
      " 71%|███████   | 292122/414113 [01:08<00:28, 4287.33it/s]\u001b[A\n",
      " 71%|███████   | 292563/414113 [01:09<00:28, 4322.42it/s]\u001b[A\n",
      " 71%|███████   | 293021/414113 [01:09<00:27, 4395.34it/s]\u001b[A\n",
      " 71%|███████   | 293462/414113 [01:09<00:27, 4398.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 293904/414113 [01:09<00:27, 4404.81it/s]\u001b[A\n",
      " 71%|███████   | 294345/414113 [01:09<00:27, 4359.48it/s]\u001b[A\n",
      " 71%|███████   | 294782/414113 [01:09<00:27, 4320.73it/s]\u001b[A\n",
      " 71%|███████▏  | 295224/414113 [01:09<00:27, 4348.24it/s]\u001b[A\n",
      " 71%|███████▏  | 295660/414113 [01:09<00:27, 4343.95it/s]\u001b[A\n",
      " 72%|███████▏  | 296095/414113 [01:09<00:27, 4313.48it/s]\u001b[A\n",
      " 72%|███████▏  | 296527/414113 [01:09<00:27, 4311.54it/s]\u001b[A\n",
      " 72%|███████▏  | 296974/414113 [01:10<00:26, 4356.48it/s]\u001b[A\n",
      " 72%|███████▏  | 297410/414113 [01:10<00:27, 4180.47it/s]\u001b[A\n",
      " 72%|███████▏  | 297844/414113 [01:10<00:27, 4226.11it/s]\u001b[A\n",
      " 72%|███████▏  | 298268/414113 [01:10<00:27, 4216.78it/s]\u001b[A\n",
      " 72%|███████▏  | 298713/414113 [01:10<00:26, 4283.21it/s]\u001b[A\n",
      " 72%|███████▏  | 299149/414113 [01:10<00:26, 4304.65it/s]\u001b[A\n",
      " 72%|███████▏  | 299581/414113 [01:10<00:26, 4292.53it/s]\u001b[A\n",
      " 72%|███████▏  | 300011/414113 [01:10<00:26, 4242.23it/s]\u001b[A\n",
      " 73%|███████▎  | 300448/414113 [01:10<00:26, 4278.22it/s]\u001b[A\n",
      " 73%|███████▎  | 300877/414113 [01:11<00:26, 4274.91it/s]\u001b[A\n",
      " 73%|███████▎  | 301305/414113 [01:11<00:26, 4270.41it/s]\u001b[A\n",
      " 73%|███████▎  | 301733/414113 [01:11<00:26, 4263.45it/s]\u001b[A\n",
      " 73%|███████▎  | 302163/414113 [01:11<00:26, 4273.33it/s]\u001b[A\n",
      " 73%|███████▎  | 302596/414113 [01:11<00:25, 4289.40it/s]\u001b[A\n",
      " 73%|███████▎  | 303027/414113 [01:11<00:25, 4292.88it/s]\u001b[A\n",
      " 73%|███████▎  | 303457/414113 [01:11<00:25, 4289.36it/s]\u001b[A\n",
      " 73%|███████▎  | 303898/414113 [01:11<00:25, 4323.17it/s]\u001b[A\n",
      " 73%|███████▎  | 304335/414113 [01:11<00:25, 4336.87it/s]\u001b[A\n",
      " 74%|███████▎  | 304769/414113 [01:11<00:25, 4328.59it/s]\u001b[A\n",
      " 74%|███████▎  | 305202/414113 [01:12<00:25, 4309.01it/s]\u001b[A\n",
      " 74%|███████▍  | 305633/414113 [01:12<00:25, 4265.02it/s]\u001b[A\n",
      " 74%|███████▍  | 306062/414113 [01:12<00:25, 4271.97it/s]\u001b[A\n",
      " 74%|███████▍  | 306504/414113 [01:12<00:24, 4314.99it/s]\u001b[A\n",
      " 74%|███████▍  | 306937/414113 [01:12<00:24, 4316.78it/s]\u001b[A\n",
      " 74%|███████▍  | 307391/414113 [01:12<00:24, 4380.10it/s]\u001b[A\n",
      " 74%|███████▍  | 307830/414113 [01:12<00:24, 4337.72it/s]\u001b[A\n",
      " 74%|███████▍  | 308274/414113 [01:12<00:24, 4365.54it/s]\u001b[A\n",
      " 75%|███████▍  | 308712/414113 [01:12<00:24, 4367.98it/s]\u001b[A\n",
      " 75%|███████▍  | 309149/414113 [01:12<00:24, 4351.25it/s]\u001b[A\n",
      " 75%|███████▍  | 309588/414113 [01:13<00:23, 4361.34it/s]\u001b[A\n",
      " 75%|███████▍  | 310038/414113 [01:13<00:23, 4401.86it/s]\u001b[A\n",
      " 75%|███████▍  | 310479/414113 [01:13<00:23, 4403.00it/s]\u001b[A\n",
      " 75%|███████▌  | 310930/414113 [01:13<00:23, 4434.09it/s]\u001b[A\n",
      " 75%|███████▌  | 311377/414113 [01:13<00:23, 4442.32it/s]\u001b[A\n",
      " 75%|███████▌  | 311822/414113 [01:13<00:23, 4441.63it/s]\u001b[A\n",
      " 75%|███████▌  | 312277/414113 [01:13<00:22, 4471.44it/s]\u001b[A\n",
      " 76%|███████▌  | 312725/414113 [01:13<00:23, 4366.68it/s]\u001b[A\n",
      " 76%|███████▌  | 313164/414113 [01:13<00:23, 4371.42it/s]\u001b[A\n",
      " 76%|███████▌  | 313602/414113 [01:13<00:22, 4372.21it/s]\u001b[A\n",
      " 76%|███████▌  | 314061/414113 [01:14<00:22, 4434.42it/s]\u001b[A\n",
      " 76%|███████▌  | 314507/414113 [01:14<00:22, 4439.80it/s]\u001b[A\n",
      " 76%|███████▌  | 314952/414113 [01:14<00:22, 4424.68it/s]\u001b[A\n",
      " 76%|███████▌  | 315398/414113 [01:14<00:22, 4433.51it/s]\u001b[A\n",
      " 76%|███████▋  | 315842/414113 [01:14<00:23, 4269.53it/s]\u001b[A\n",
      " 76%|███████▋  | 316271/414113 [01:14<00:23, 4247.48it/s]\u001b[A\n",
      " 76%|███████▋  | 316720/414113 [01:14<00:22, 4315.84it/s]\u001b[A\n",
      " 77%|███████▋  | 317160/414113 [01:14<00:22, 4338.11it/s]\u001b[A\n",
      " 77%|███████▋  | 317595/414113 [01:14<00:22, 4304.43it/s]\u001b[A\n",
      " 77%|███████▋  | 318032/414113 [01:14<00:22, 4323.29it/s]\u001b[A\n",
      " 77%|███████▋  | 318471/414113 [01:15<00:22, 4342.45it/s]\u001b[A\n",
      " 77%|███████▋  | 318919/414113 [01:15<00:21, 4381.07it/s]\u001b[A\n",
      " 77%|███████▋  | 319377/414113 [01:15<00:21, 4438.57it/s]\u001b[A\n",
      " 77%|███████▋  | 319822/414113 [01:15<00:21, 4419.66it/s]\u001b[A\n",
      " 77%|███████▋  | 320265/414113 [01:15<00:21, 4420.12it/s]\u001b[A\n",
      " 77%|███████▋  | 320715/414113 [01:15<00:21, 4441.39it/s]\u001b[A\n",
      " 78%|███████▊  | 321160/414113 [01:15<00:21, 4393.02it/s]\u001b[A\n",
      " 78%|███████▊  | 321617/414113 [01:15<00:20, 4442.69it/s]\u001b[A\n",
      " 78%|███████▊  | 322062/414113 [01:15<00:20, 4415.35it/s]\u001b[A\n",
      " 78%|███████▊  | 322523/414113 [01:15<00:20, 4470.44it/s]\u001b[A\n",
      " 78%|███████▊  | 322971/414113 [01:16<00:21, 4242.82it/s]\u001b[A\n",
      " 78%|███████▊  | 323413/414113 [01:16<00:21, 4294.02it/s]\u001b[A\n",
      " 78%|███████▊  | 323845/414113 [01:16<00:20, 4299.42it/s]\u001b[A\n",
      " 78%|███████▊  | 324280/414113 [01:16<00:20, 4312.23it/s]\u001b[A\n",
      " 78%|███████▊  | 324737/414113 [01:16<00:20, 4384.83it/s]\u001b[A\n",
      " 79%|███████▊  | 325184/414113 [01:16<00:20, 4409.56it/s]\u001b[A\n",
      " 79%|███████▊  | 325626/414113 [01:16<00:20, 4394.96it/s]\u001b[A\n",
      " 79%|███████▊  | 326067/414113 [01:16<00:20, 4322.61it/s]\u001b[A\n",
      " 79%|███████▉  | 326500/414113 [01:17<00:42, 2038.04it/s]\u001b[A\n",
      " 79%|███████▉  | 326950/414113 [01:17<00:35, 2437.53it/s]\u001b[A\n",
      " 79%|███████▉  | 327390/414113 [01:17<00:30, 2813.97it/s]\u001b[A\n",
      " 79%|███████▉  | 327818/414113 [01:17<00:27, 3135.48it/s]\u001b[A\n",
      " 79%|███████▉  | 328219/414113 [01:17<00:26, 3293.37it/s]\u001b[A\n",
      " 79%|███████▉  | 328663/414113 [01:17<00:23, 3569.83it/s]\u001b[A\n",
      " 79%|███████▉  | 329092/414113 [01:17<00:22, 3757.80it/s]\u001b[A\n",
      " 80%|███████▉  | 329532/414113 [01:17<00:21, 3929.27it/s]\u001b[A\n",
      " 80%|███████▉  | 329954/414113 [01:18<00:21, 3992.61it/s]\u001b[A\n",
      " 80%|███████▉  | 330390/414113 [01:18<00:20, 4095.29it/s]\u001b[A\n",
      " 80%|███████▉  | 330815/414113 [01:18<00:20, 4110.34it/s]\u001b[A\n",
      " 80%|███████▉  | 331237/414113 [01:18<00:20, 4080.86it/s]\u001b[A\n",
      " 80%|████████  | 331653/414113 [01:18<00:20, 4073.75it/s]\u001b[A\n",
      " 80%|████████  | 332070/414113 [01:18<00:20, 4100.67it/s]\u001b[A\n",
      " 80%|████████  | 332498/414113 [01:18<00:19, 4151.14it/s]\u001b[A\n",
      " 80%|████████  | 332922/414113 [01:18<00:19, 4176.65it/s]\u001b[A\n",
      " 80%|████████  | 333342/414113 [01:18<00:19, 4154.03it/s]\u001b[A\n",
      " 81%|████████  | 333781/414113 [01:18<00:19, 4221.01it/s]\u001b[A\n",
      " 81%|████████  | 334225/414113 [01:19<00:18, 4283.22it/s]\u001b[A\n",
      " 81%|████████  | 334667/414113 [01:19<00:18, 4322.79it/s]\u001b[A\n",
      " 81%|████████  | 335101/414113 [01:19<00:18, 4327.08it/s]\u001b[A\n",
      " 81%|████████  | 335535/414113 [01:19<00:18, 4292.90it/s]\u001b[A\n",
      " 81%|████████  | 335976/414113 [01:19<00:18, 4325.54it/s]\u001b[A\n",
      " 81%|████████  | 336410/414113 [01:19<00:17, 4329.76it/s]\u001b[A\n",
      " 81%|████████▏ | 336844/414113 [01:19<00:17, 4320.75it/s]\u001b[A\n",
      " 81%|████████▏ | 337277/414113 [01:19<00:17, 4296.41it/s]\u001b[A\n",
      " 82%|████████▏ | 337707/414113 [01:19<00:17, 4287.79it/s]\u001b[A\n",
      " 82%|████████▏ | 338152/414113 [01:20<00:17, 4335.12it/s]\u001b[A\n",
      " 82%|████████▏ | 338586/414113 [01:20<00:17, 4309.01it/s]\u001b[A\n",
      " 82%|████████▏ | 339018/414113 [01:20<00:17, 4296.82it/s]\u001b[A\n",
      " 82%|████████▏ | 339448/414113 [01:20<00:17, 4269.57it/s]\u001b[A\n",
      " 82%|████████▏ | 339881/414113 [01:20<00:17, 4285.06it/s]\u001b[A\n",
      " 82%|████████▏ | 340320/414113 [01:20<00:17, 4315.78it/s]\u001b[A\n",
      " 82%|████████▏ | 340765/414113 [01:20<00:16, 4353.12it/s]\u001b[A\n",
      " 82%|████████▏ | 341201/414113 [01:20<00:17, 4183.02it/s]\u001b[A\n",
      " 83%|████████▎ | 341653/414113 [01:20<00:16, 4277.81it/s]\u001b[A\n",
      " 83%|████████▎ | 342083/414113 [01:20<00:16, 4279.71it/s]\u001b[A\n",
      " 83%|████████▎ | 342518/414113 [01:21<00:16, 4298.26it/s]\u001b[A\n",
      " 83%|████████▎ | 342949/414113 [01:21<00:17, 4077.73it/s]\u001b[A\n",
      " 83%|████████▎ | 343398/414113 [01:21<00:16, 4192.99it/s]\u001b[A\n",
      " 83%|████████▎ | 343823/414113 [01:21<00:16, 4207.50it/s]\u001b[A\n",
      " 83%|████████▎ | 344249/414113 [01:21<00:16, 4220.72it/s]\u001b[A\n",
      " 83%|████████▎ | 344673/414113 [01:21<00:16, 4199.82it/s]\u001b[A\n",
      " 83%|████████▎ | 345094/414113 [01:21<00:17, 4030.45it/s]\u001b[A\n",
      " 83%|████████▎ | 345505/414113 [01:21<00:16, 4053.53it/s]\u001b[A\n",
      " 84%|████████▎ | 345933/414113 [01:21<00:16, 4117.17it/s]\u001b[A\n",
      " 84%|████████▎ | 346367/414113 [01:21<00:16, 4179.98it/s]\u001b[A\n",
      " 84%|████████▎ | 346791/414113 [01:22<00:16, 4195.19it/s]\u001b[A\n",
      " 84%|████████▍ | 347212/414113 [01:22<00:15, 4195.14it/s]\u001b[A\n",
      " 84%|████████▍ | 347644/414113 [01:22<00:15, 4229.58it/s]\u001b[A\n",
      " 84%|████████▍ | 348082/414113 [01:22<00:15, 4272.08it/s]\u001b[A\n",
      " 84%|████████▍ | 348517/414113 [01:22<00:15, 4294.70it/s]\u001b[A\n",
      " 84%|████████▍ | 348947/414113 [01:22<00:15, 4280.49it/s]\u001b[A\n",
      " 84%|████████▍ | 349385/414113 [01:22<00:15, 4307.69it/s]\u001b[A\n",
      " 84%|████████▍ | 349820/414113 [01:22<00:14, 4320.05it/s]\u001b[A\n",
      " 85%|████████▍ | 350267/414113 [01:22<00:14, 4362.34it/s]\u001b[A\n",
      " 85%|████████▍ | 350704/414113 [01:22<00:14, 4316.02it/s]\u001b[A\n",
      " 85%|████████▍ | 351136/414113 [01:23<00:14, 4272.18it/s]\u001b[A\n",
      " 85%|████████▍ | 351567/414113 [01:23<00:14, 4280.41it/s]\u001b[A\n",
      " 85%|████████▌ | 351997/414113 [01:23<00:14, 4286.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 352436/414113 [01:23<00:14, 4316.78it/s]\u001b[A\n",
      " 85%|████████▌ | 352872/414113 [01:23<00:14, 4329.29it/s]\u001b[A\n",
      " 85%|████████▌ | 353306/414113 [01:23<00:14, 4302.04it/s]\u001b[A\n",
      " 85%|████████▌ | 353742/414113 [01:23<00:13, 4319.19it/s]\u001b[A\n",
      " 86%|████████▌ | 354185/414113 [01:23<00:13, 4351.58it/s]\u001b[A\n",
      " 86%|████████▌ | 354627/414113 [01:23<00:13, 4370.22it/s]\u001b[A\n",
      " 86%|████████▌ | 355076/414113 [01:23<00:13, 4403.73it/s]\u001b[A\n",
      " 86%|████████▌ | 355517/414113 [01:24<00:13, 4360.15it/s]\u001b[A\n",
      " 86%|████████▌ | 355954/414113 [01:24<00:13, 4317.76it/s]\u001b[A\n",
      " 86%|████████▌ | 356387/414113 [01:24<00:13, 4304.88it/s]\u001b[A\n",
      " 86%|████████▌ | 356830/414113 [01:24<00:13, 4340.48it/s]\u001b[A\n",
      " 86%|████████▋ | 357265/414113 [01:24<00:13, 4322.55it/s]\u001b[A\n",
      " 86%|████████▋ | 357698/414113 [01:24<00:13, 4274.72it/s]\u001b[A\n",
      " 86%|████████▋ | 358126/414113 [01:24<00:13, 4242.98it/s]\u001b[A\n",
      " 87%|████████▋ | 358551/414113 [01:24<00:13, 4231.05it/s]\u001b[A\n",
      " 87%|████████▋ | 358994/414113 [01:24<00:12, 4288.38it/s]\u001b[A\n",
      " 87%|████████▋ | 359424/414113 [01:24<00:12, 4284.71it/s]\u001b[A\n",
      " 87%|████████▋ | 359853/414113 [01:25<00:12, 4270.39it/s]\u001b[A\n",
      " 87%|████████▋ | 360287/414113 [01:25<00:12, 4289.59it/s]\u001b[A\n",
      " 87%|████████▋ | 360720/414113 [01:25<00:12, 4301.28it/s]\u001b[A\n",
      " 87%|████████▋ | 361163/414113 [01:25<00:12, 4337.62it/s]\u001b[A\n",
      " 87%|████████▋ | 361597/414113 [01:25<00:12, 4284.28it/s]\u001b[A\n",
      " 87%|████████▋ | 362043/414113 [01:25<00:12, 4334.39it/s]\u001b[A\n",
      " 88%|████████▊ | 362477/414113 [01:25<00:12, 4203.98it/s]\u001b[A\n",
      " 88%|████████▊ | 362899/414113 [01:25<00:12, 4080.16it/s]\u001b[A\n",
      " 88%|████████▊ | 363323/414113 [01:25<00:12, 4123.02it/s]\u001b[A\n",
      " 88%|████████▊ | 363737/414113 [01:26<00:12, 4043.99it/s]\u001b[A\n",
      " 88%|████████▊ | 364152/414113 [01:26<00:12, 4074.07it/s]\u001b[A\n",
      " 88%|████████▊ | 364585/414113 [01:26<00:11, 4145.25it/s]\u001b[A\n",
      " 88%|████████▊ | 365001/414113 [01:26<00:12, 4033.87it/s]\u001b[A\n",
      " 88%|████████▊ | 365406/414113 [01:26<00:12, 4026.15it/s]\u001b[A\n",
      " 88%|████████▊ | 365830/414113 [01:26<00:11, 4085.91it/s]\u001b[A\n",
      " 88%|████████▊ | 366267/414113 [01:26<00:11, 4165.53it/s]\u001b[A\n",
      " 89%|████████▊ | 366722/414113 [01:26<00:11, 4270.90it/s]\u001b[A\n",
      " 89%|████████▊ | 367154/414113 [01:26<00:10, 4283.08it/s]\u001b[A\n",
      " 89%|████████▉ | 367584/414113 [01:26<00:11, 4206.74it/s]\u001b[A\n",
      " 89%|████████▉ | 368006/414113 [01:27<00:11, 4008.26it/s]\u001b[A\n",
      " 89%|████████▉ | 368450/414113 [01:27<00:11, 4128.24it/s]\u001b[A\n",
      " 89%|████████▉ | 368893/414113 [01:27<00:10, 4212.98it/s]\u001b[A\n",
      " 89%|████████▉ | 369317/414113 [01:27<00:10, 4180.27it/s]\u001b[A\n",
      " 89%|████████▉ | 369743/414113 [01:27<00:10, 4200.23it/s]\u001b[A\n",
      " 89%|████████▉ | 370165/414113 [01:27<00:10, 4188.14it/s]\u001b[A\n",
      " 89%|████████▉ | 370585/414113 [01:27<00:11, 3951.95it/s]\u001b[A\n",
      " 90%|████████▉ | 371006/414113 [01:27<00:10, 4022.62it/s]\u001b[A\n",
      " 90%|████████▉ | 371415/414113 [01:27<00:10, 4040.93it/s]\u001b[A\n",
      " 90%|████████▉ | 371832/414113 [01:27<00:10, 4076.21it/s]\u001b[A\n",
      " 90%|████████▉ | 372242/414113 [01:28<00:10, 4062.34it/s]\u001b[A\n",
      " 90%|████████▉ | 372650/414113 [01:28<00:10, 4057.65it/s]\u001b[A\n",
      " 90%|█████████ | 373057/414113 [01:28<00:10, 3993.24it/s]\u001b[A\n",
      " 90%|█████████ | 373458/414113 [01:28<00:10, 3945.80it/s]\u001b[A\n",
      " 90%|█████████ | 373865/414113 [01:28<00:10, 3978.67it/s]\u001b[A\n",
      " 90%|█████████ | 374276/414113 [01:28<00:09, 4016.45it/s]\u001b[A\n",
      " 90%|█████████ | 374700/414113 [01:28<00:09, 4079.85it/s]\u001b[A\n",
      " 91%|█████████ | 375118/414113 [01:28<00:09, 4107.49it/s]\u001b[A\n",
      " 91%|█████████ | 375545/414113 [01:28<00:09, 4152.97it/s]\u001b[A\n",
      " 91%|█████████ | 375964/414113 [01:28<00:09, 4161.12it/s]\u001b[A\n",
      " 91%|█████████ | 376387/414113 [01:29<00:09, 4180.71it/s]\u001b[A\n",
      " 91%|█████████ | 376808/414113 [01:29<00:08, 4187.83it/s]\u001b[A\n",
      " 91%|█████████ | 377227/414113 [01:29<00:08, 4163.97it/s]\u001b[A\n",
      " 91%|█████████ | 377667/414113 [01:29<00:08, 4230.61it/s]\u001b[A\n",
      " 91%|█████████▏| 378091/414113 [01:29<00:08, 4206.53it/s]\u001b[A\n",
      " 91%|█████████▏| 378522/414113 [01:29<00:08, 4236.67it/s]\u001b[A\n",
      " 92%|█████████▏| 378969/414113 [01:29<00:08, 4303.73it/s]\u001b[A\n",
      " 92%|█████████▏| 379400/414113 [01:29<00:08, 4275.70it/s]\u001b[A\n",
      " 92%|█████████▏| 379828/414113 [01:29<00:08, 4264.34it/s]\u001b[A\n",
      " 92%|█████████▏| 380266/414113 [01:30<00:07, 4296.76it/s]\u001b[A\n",
      " 92%|█████████▏| 380697/414113 [01:30<00:07, 4299.98it/s]\u001b[A\n",
      " 92%|█████████▏| 381151/414113 [01:30<00:07, 4368.35it/s]\u001b[A\n",
      " 92%|█████████▏| 381589/414113 [01:30<00:07, 4364.30it/s]\u001b[A\n",
      " 92%|█████████▏| 382026/414113 [01:30<00:07, 4344.33it/s]\u001b[A\n",
      " 92%|█████████▏| 382461/414113 [01:30<00:07, 4322.48it/s]\u001b[A\n",
      " 92%|█████████▏| 382918/414113 [01:30<00:07, 4391.96it/s]\u001b[A\n",
      " 93%|█████████▎| 383358/414113 [01:30<00:07, 4337.99it/s]\u001b[A\n",
      " 93%|█████████▎| 383793/414113 [01:30<00:07, 4315.20it/s]\u001b[A\n",
      " 93%|█████████▎| 384225/414113 [01:30<00:06, 4282.25it/s]\u001b[A\n",
      " 93%|█████████▎| 384654/414113 [01:31<00:06, 4269.40it/s]\u001b[A\n",
      " 93%|█████████▎| 385094/414113 [01:31<00:06, 4307.04it/s]\u001b[A\n",
      " 93%|█████████▎| 385525/414113 [01:31<00:07, 4010.32it/s]\u001b[A\n",
      " 93%|█████████▎| 385932/414113 [01:31<00:06, 4026.19it/s]\u001b[A\n",
      " 93%|█████████▎| 386351/414113 [01:31<00:06, 4073.55it/s]\u001b[A\n",
      " 93%|█████████▎| 386793/414113 [01:31<00:06, 4170.33it/s]\u001b[A\n",
      " 94%|█████████▎| 387217/414113 [01:31<00:06, 4190.05it/s]\u001b[A\n",
      " 94%|█████████▎| 387647/414113 [01:31<00:06, 4219.90it/s]\u001b[A\n",
      " 94%|█████████▎| 388071/414113 [01:31<00:06, 4211.76it/s]\u001b[A\n",
      " 94%|█████████▍| 388495/414113 [01:31<00:06, 4219.30it/s]\u001b[A\n",
      " 94%|█████████▍| 388925/414113 [01:32<00:05, 4241.30it/s]\u001b[A\n",
      " 94%|█████████▍| 389372/414113 [01:32<00:05, 4304.94it/s]\u001b[A\n",
      " 94%|█████████▍| 389804/414113 [01:32<00:05, 4304.33it/s]\u001b[A\n",
      " 94%|█████████▍| 390235/414113 [01:32<00:05, 4303.63it/s]\u001b[A\n",
      " 94%|█████████▍| 390666/414113 [01:32<00:05, 4286.28it/s]\u001b[A\n",
      " 94%|█████████▍| 391095/414113 [01:32<00:05, 4276.84it/s]\u001b[A\n",
      " 95%|█████████▍| 391523/414113 [01:32<00:05, 4191.86it/s]\u001b[A\n",
      " 95%|█████████▍| 391955/414113 [01:32<00:05, 4228.68it/s]\u001b[A\n",
      " 95%|█████████▍| 392379/414113 [01:32<00:05, 4224.25it/s]\u001b[A\n",
      " 95%|█████████▍| 392802/414113 [01:32<00:05, 4178.78it/s]\u001b[A\n",
      " 95%|█████████▍| 393221/414113 [01:33<00:05, 4139.97it/s]\u001b[A\n",
      " 95%|█████████▌| 393662/414113 [01:33<00:04, 4216.66it/s]\u001b[A\n",
      " 95%|█████████▌| 394085/414113 [01:33<00:04, 4213.62it/s]\u001b[A\n",
      " 95%|█████████▌| 394517/414113 [01:33<00:04, 4241.59it/s]\u001b[A\n",
      " 95%|█████████▌| 394942/414113 [01:33<00:04, 4226.45it/s]\u001b[A\n",
      " 95%|█████████▌| 395366/414113 [01:33<00:04, 4230.00it/s]\u001b[A\n",
      " 96%|█████████▌| 395790/414113 [01:33<00:04, 4225.38it/s]\u001b[A\n",
      " 96%|█████████▌| 396213/414113 [01:33<00:04, 4026.00it/s]\u001b[A\n",
      " 96%|█████████▌| 396643/414113 [01:33<00:04, 4101.38it/s]\u001b[A\n",
      " 96%|█████████▌| 397058/414113 [01:33<00:04, 4114.81it/s]\u001b[A\n",
      " 96%|█████████▌| 397486/414113 [01:34<00:03, 4160.91it/s]\u001b[A\n",
      " 96%|█████████▌| 397929/414113 [01:34<00:03, 4237.03it/s]\u001b[A\n",
      " 96%|█████████▌| 398367/414113 [01:34<00:03, 4276.04it/s]\u001b[A\n",
      " 96%|█████████▋| 398810/414113 [01:34<00:03, 4320.26it/s]\u001b[A\n",
      " 96%|█████████▋| 399243/414113 [01:34<00:03, 4273.72it/s]\u001b[A\n",
      " 97%|█████████▋| 399671/414113 [01:34<00:03, 4262.95it/s]\u001b[A\n",
      " 97%|█████████▋| 400106/414113 [01:34<00:03, 4287.19it/s]\u001b[A\n",
      " 97%|█████████▋| 400536/414113 [01:34<00:03, 4167.75it/s]\u001b[A\n",
      " 97%|█████████▋| 400978/414113 [01:34<00:03, 4239.00it/s]\u001b[A\n",
      " 97%|█████████▋| 401403/414113 [01:35<00:03, 4207.85it/s]\u001b[A\n",
      " 97%|█████████▋| 401829/414113 [01:35<00:02, 4221.66it/s]\u001b[A\n",
      " 97%|█████████▋| 402252/414113 [01:35<00:02, 4125.44it/s]\u001b[A\n",
      " 97%|█████████▋| 402666/414113 [01:35<00:02, 4101.23it/s]\u001b[A\n",
      " 97%|█████████▋| 403100/414113 [01:35<00:02, 4168.62it/s]\u001b[A\n",
      " 97%|█████████▋| 403534/414113 [01:35<00:02, 4217.98it/s]\u001b[A\n",
      " 98%|█████████▊| 403976/414113 [01:35<00:02, 4274.98it/s]\u001b[A\n",
      " 98%|█████████▊| 404405/414113 [01:35<00:02, 4261.99it/s]\u001b[A\n",
      " 98%|█████████▊| 404838/414113 [01:35<00:02, 4281.14it/s]\u001b[A\n",
      " 98%|█████████▊| 405268/414113 [01:35<00:02, 4284.56it/s]\u001b[A\n",
      " 98%|█████████▊| 405697/414113 [01:36<00:01, 4281.77it/s]\u001b[A\n",
      " 98%|█████████▊| 406128/414113 [01:36<00:01, 4289.93it/s]\u001b[A\n",
      " 98%|█████████▊| 406558/414113 [01:36<00:01, 4279.29it/s]\u001b[A\n",
      " 98%|█████████▊| 406987/414113 [01:36<00:01, 4276.46it/s]\u001b[A\n",
      " 98%|█████████▊| 407431/414113 [01:36<00:01, 4324.12it/s]\u001b[A\n",
      " 98%|█████████▊| 407864/414113 [01:36<00:01, 4103.56it/s]\u001b[A\n",
      " 99%|█████████▊| 408277/414113 [01:36<00:01, 3878.89it/s]\u001b[A\n",
      " 99%|█████████▊| 408702/414113 [01:36<00:01, 3981.98it/s]\u001b[A\n",
      " 99%|█████████▉| 409130/414113 [01:36<00:01, 4065.08it/s]\u001b[A\n",
      " 99%|█████████▉| 409558/414113 [01:36<00:01, 4125.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 409990/414113 [01:37<00:00, 4181.02it/s]\u001b[A\n",
      " 99%|█████████▉| 410424/414113 [01:37<00:00, 4226.82it/s]\u001b[A\n",
      " 99%|█████████▉| 410857/414113 [01:37<00:00, 4256.18it/s]\u001b[A\n",
      " 99%|█████████▉| 411284/414113 [01:37<00:00, 4194.85it/s]\u001b[A\n",
      " 99%|█████████▉| 411705/414113 [01:37<00:00, 4045.17it/s]\u001b[A\n",
      "100%|█████████▉| 412128/414113 [01:37<00:00, 4096.61it/s]\u001b[A\n",
      "100%|█████████▉| 412558/414113 [01:37<00:00, 4154.07it/s]\u001b[A\n",
      "100%|█████████▉| 412994/414113 [01:37<00:00, 4212.33it/s]\u001b[A\n",
      "100%|█████████▉| 413432/414113 [01:37<00:00, 4259.49it/s]\u001b[A\n",
      "100%|█████████▉| 413859/414113 [01:37<00:00, 4198.85it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:38<00:00, 4223.81it/s]\u001b[ADownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "\n",
      "  0%|          | 0/102502400 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 229376/102502400 [00:00<01:47, 948763.42it/s]\u001b[A\n",
      "  5%|▌         | 5152768/102502400 [00:00<01:12, 1344261.87it/s]\u001b[A\n",
      " 15%|█▍        | 15245312/102502400 [00:00<00:45, 1909465.64it/s]\u001b[A\n",
      " 24%|██▍       | 24584192/102502400 [00:00<00:28, 2704103.89it/s]\u001b[A\n",
      " 33%|███▎      | 34021376/102502400 [00:00<00:17, 3816118.25it/s]\u001b[A\n",
      " 42%|████▏     | 43147264/102502400 [00:00<00:11, 5355535.59it/s]\u001b[A\n",
      " 51%|█████▏    | 52756480/102502400 [00:00<00:06, 7472237.92it/s]\u001b[A\n",
      " 62%|██████▏   | 63184896/102502400 [00:00<00:03, 10356503.69it/s]\u001b[A\n",
      " 72%|███████▏  | 74014720/102502400 [00:01<00:02, 14212264.29it/s]\u001b[A\n",
      " 82%|████████▏ | 83681280/102502400 [00:01<00:00, 19099371.59it/s]\u001b[A\n",
      " 91%|█████████ | 93503488/102502400 [00:01<00:00, 25184638.00it/s]\u001b[A\n",
      "100%|██████████| 102502400/102502400 [00:01<00:00, 77089985.97it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr = 0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/6471], Loss: 4.0654, Perplexity: 58.2867\n",
      "Epoch [1/3], Step [200/6471], Loss: 3.2664, Perplexity: 26.2162\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.4442, Perplexity: 31.3180\n",
      "Epoch [1/3], Step [400/6471], Loss: 3.1852, Perplexity: 24.1732\n",
      "Epoch [1/3], Step [500/6471], Loss: 2.9120, Perplexity: 18.3932\n",
      "Epoch [1/3], Step [600/6471], Loss: 2.6098, Perplexity: 13.5968\n",
      "Epoch [1/3], Step [700/6471], Loss: 2.5509, Perplexity: 12.8189\n",
      "Epoch [1/3], Step [800/6471], Loss: 2.4945, Perplexity: 12.1152\n",
      "Epoch [1/3], Step [900/6471], Loss: 2.8575, Perplexity: 17.4174\n",
      "Epoch [1/3], Step [1000/6471], Loss: 2.7678, Perplexity: 15.9238\n",
      "Epoch [1/3], Step [1100/6471], Loss: 2.7478, Perplexity: 15.6085\n",
      "Epoch [1/3], Step [1200/6471], Loss: 2.3031, Perplexity: 10.0047\n",
      "Epoch [1/3], Step [1300/6471], Loss: 2.7339, Perplexity: 15.3924\n",
      "Epoch [1/3], Step [1400/6471], Loss: 2.5599, Perplexity: 12.9344\n",
      "Epoch [1/3], Step [1500/6471], Loss: 2.3193, Perplexity: 10.1686\n",
      "Epoch [1/3], Step [1600/6471], Loss: 2.3959, Perplexity: 10.9775\n",
      "Epoch [1/3], Step [1700/6471], Loss: 2.5677, Perplexity: 13.0363\n",
      "Epoch [1/3], Step [1800/6471], Loss: 2.5309, Perplexity: 12.5651\n",
      "Epoch [1/3], Step [1900/6471], Loss: 2.3952, Perplexity: 10.9707\n",
      "Epoch [1/3], Step [2000/6471], Loss: 2.1950, Perplexity: 8.98034\n",
      "Epoch [1/3], Step [2100/6471], Loss: 2.4059, Perplexity: 11.0884\n",
      "Epoch [1/3], Step [2200/6471], Loss: 2.9394, Perplexity: 18.9046\n",
      "Epoch [1/3], Step [2300/6471], Loss: 2.3215, Perplexity: 10.1912\n",
      "Epoch [1/3], Step [2400/6471], Loss: 2.2057, Perplexity: 9.07631\n",
      "Epoch [1/3], Step [2500/6471], Loss: 2.2866, Perplexity: 9.84121\n",
      "Epoch [1/3], Step [2600/6471], Loss: 2.2136, Perplexity: 9.14903\n",
      "Epoch [1/3], Step [2700/6471], Loss: 2.2616, Perplexity: 9.59874\n",
      "Epoch [1/3], Step [2800/6471], Loss: 2.4499, Perplexity: 11.5874\n",
      "Epoch [1/3], Step [2900/6471], Loss: 2.0747, Perplexity: 7.96180\n",
      "Epoch [1/3], Step [3000/6471], Loss: 2.7439, Perplexity: 15.5478\n",
      "Epoch [1/3], Step [3100/6471], Loss: 2.0697, Perplexity: 7.92275\n",
      "Epoch [1/3], Step [3200/6471], Loss: 2.0646, Perplexity: 7.88239\n",
      "Epoch [1/3], Step [3300/6471], Loss: 2.2736, Perplexity: 9.71409\n",
      "Epoch [1/3], Step [3400/6471], Loss: 2.2021, Perplexity: 9.04411\n",
      "Epoch [1/3], Step [3500/6471], Loss: 2.5994, Perplexity: 13.4558\n",
      "Epoch [1/3], Step [3600/6471], Loss: 1.9683, Perplexity: 7.15864\n",
      "Epoch [1/3], Step [3700/6471], Loss: 2.1209, Perplexity: 8.33877\n",
      "Epoch [1/3], Step [3800/6471], Loss: 2.1053, Perplexity: 8.20953\n",
      "Epoch [1/3], Step [3900/6471], Loss: 2.1285, Perplexity: 8.40263\n",
      "Epoch [1/3], Step [4000/6471], Loss: 2.0631, Perplexity: 7.87015\n",
      "Epoch [1/3], Step [4100/6471], Loss: 2.0475, Perplexity: 7.74856\n",
      "Epoch [1/3], Step [4200/6471], Loss: 2.7333, Perplexity: 15.3843\n",
      "Epoch [1/3], Step [4300/6471], Loss: 1.9647, Perplexity: 7.13289\n",
      "Epoch [1/3], Step [4400/6471], Loss: 2.1804, Perplexity: 8.85024\n",
      "Epoch [1/3], Step [4500/6471], Loss: 2.4419, Perplexity: 11.4943\n",
      "Epoch [1/3], Step [4600/6471], Loss: 2.3224, Perplexity: 10.1997\n",
      "Epoch [1/3], Step [4700/6471], Loss: 2.3762, Perplexity: 10.7641\n",
      "Epoch [1/3], Step [4800/6471], Loss: 2.1962, Perplexity: 8.99047\n",
      "Epoch [1/3], Step [4900/6471], Loss: 2.1513, Perplexity: 8.59598\n",
      "Epoch [1/3], Step [5000/6471], Loss: 2.1325, Perplexity: 8.43637\n",
      "Epoch [1/3], Step [5100/6471], Loss: 2.0156, Perplexity: 7.50536\n",
      "Epoch [1/3], Step [5200/6471], Loss: 2.1478, Perplexity: 8.56578\n",
      "Epoch [1/3], Step [5300/6471], Loss: 2.0409, Perplexity: 7.69735\n",
      "Epoch [1/3], Step [5400/6471], Loss: 2.4217, Perplexity: 11.2645\n",
      "Epoch [1/3], Step [5500/6471], Loss: 2.0630, Perplexity: 7.86956\n",
      "Epoch [1/3], Step [5600/6471], Loss: 2.0779, Perplexity: 7.98796\n",
      "Epoch [1/3], Step [5700/6471], Loss: 2.1329, Perplexity: 8.43931\n",
      "Epoch [1/3], Step [5800/6471], Loss: 2.1059, Perplexity: 8.21470\n",
      "Epoch [1/3], Step [5900/6471], Loss: 1.9466, Perplexity: 7.00480\n",
      "Epoch [1/3], Step [6000/6471], Loss: 1.8623, Perplexity: 6.43863\n",
      "Epoch [1/3], Step [6100/6471], Loss: 2.2620, Perplexity: 9.60206\n",
      "Epoch [1/3], Step [6200/6471], Loss: 2.1862, Perplexity: 8.90109\n",
      "Epoch [1/3], Step [6300/6471], Loss: 2.2056, Perplexity: 9.07616\n",
      "Epoch [1/3], Step [6400/6471], Loss: 2.0779, Perplexity: 7.98783\n",
      "Epoch [2/3], Step [100/6471], Loss: 2.3017, Perplexity: 9.990878\n",
      "Epoch [2/3], Step [200/6471], Loss: 1.9926, Perplexity: 7.33468\n",
      "Epoch [2/3], Step [300/6471], Loss: 1.8296, Perplexity: 6.23144\n",
      "Epoch [2/3], Step [400/6471], Loss: 2.5844, Perplexity: 13.2557\n",
      "Epoch [2/3], Step [500/6471], Loss: 2.1146, Perplexity: 8.28642\n",
      "Epoch [2/3], Step [600/6471], Loss: 2.2130, Perplexity: 9.14309\n",
      "Epoch [2/3], Step [700/6471], Loss: 2.0166, Perplexity: 7.51250\n",
      "Epoch [2/3], Step [800/6471], Loss: 1.9637, Perplexity: 7.12555\n",
      "Epoch [2/3], Step [900/6471], Loss: 2.0094, Perplexity: 7.45884\n",
      "Epoch [2/3], Step [1000/6471], Loss: 2.1854, Perplexity: 8.8940\n",
      "Epoch [2/3], Step [1100/6471], Loss: 2.0719, Perplexity: 7.93956\n",
      "Epoch [2/3], Step [1200/6471], Loss: 1.9692, Perplexity: 7.16474\n",
      "Epoch [2/3], Step [1300/6471], Loss: 2.0139, Perplexity: 7.49267\n",
      "Epoch [2/3], Step [1400/6471], Loss: 1.9156, Perplexity: 6.79116\n",
      "Epoch [2/3], Step [1500/6471], Loss: 1.9627, Perplexity: 7.11840\n",
      "Epoch [2/3], Step [1600/6471], Loss: 1.7999, Perplexity: 6.04918\n",
      "Epoch [2/3], Step [1700/6471], Loss: 1.9814, Perplexity: 7.25276\n",
      "Epoch [2/3], Step [1800/6471], Loss: 1.9224, Perplexity: 6.83728\n",
      "Epoch [2/3], Step [1900/6471], Loss: 1.9223, Perplexity: 6.83659\n",
      "Epoch [2/3], Step [2000/6471], Loss: 2.0766, Perplexity: 7.97746\n",
      "Epoch [2/3], Step [2100/6471], Loss: 2.0385, Perplexity: 7.67895\n",
      "Epoch [2/3], Step [2200/6471], Loss: 2.0676, Perplexity: 7.90553\n",
      "Epoch [2/3], Step [2300/6471], Loss: 2.2688, Perplexity: 9.66778\n",
      "Epoch [2/3], Step [2400/6471], Loss: 2.1224, Perplexity: 8.35109\n",
      "Epoch [2/3], Step [2500/6471], Loss: 1.9808, Perplexity: 7.24870\n",
      "Epoch [2/3], Step [2600/6471], Loss: 1.9416, Perplexity: 6.96968\n",
      "Epoch [2/3], Step [2700/6471], Loss: 1.9489, Perplexity: 7.02076\n",
      "Epoch [2/3], Step [2800/6471], Loss: 2.2766, Perplexity: 9.74307\n",
      "Epoch [2/3], Step [2900/6471], Loss: 1.9174, Perplexity: 6.80357\n",
      "Epoch [2/3], Step [3000/6471], Loss: 2.1504, Perplexity: 8.58814\n",
      "Epoch [2/3], Step [3100/6471], Loss: 2.0427, Perplexity: 7.71126\n",
      "Epoch [2/3], Step [3200/6471], Loss: 1.8747, Perplexity: 6.51892\n",
      "Epoch [2/3], Step [3300/6471], Loss: 2.1347, Perplexity: 8.45478\n",
      "Epoch [2/3], Step [3400/6471], Loss: 1.8023, Perplexity: 6.06342\n",
      "Epoch [2/3], Step [3500/6471], Loss: 1.7838, Perplexity: 5.95242\n",
      "Epoch [2/3], Step [3600/6471], Loss: 1.9512, Perplexity: 7.03711\n",
      "Epoch [2/3], Step [3700/6471], Loss: 1.9108, Perplexity: 6.75875\n",
      "Epoch [2/3], Step [3800/6471], Loss: 2.2070, Perplexity: 9.08844\n",
      "Epoch [2/3], Step [3900/6471], Loss: 2.2523, Perplexity: 9.51006\n",
      "Epoch [2/3], Step [4000/6471], Loss: 1.8297, Perplexity: 6.23209\n",
      "Epoch [2/3], Step [4100/6471], Loss: 2.0595, Perplexity: 7.84228\n",
      "Epoch [2/3], Step [4200/6471], Loss: 1.7276, Perplexity: 5.62717\n",
      "Epoch [2/3], Step [4300/6471], Loss: 1.9175, Perplexity: 6.80398\n",
      "Epoch [2/3], Step [4400/6471], Loss: 1.9959, Perplexity: 7.35910\n",
      "Epoch [2/3], Step [4500/6471], Loss: 2.0439, Perplexity: 7.72056\n",
      "Epoch [2/3], Step [4600/6471], Loss: 1.7179, Perplexity: 5.57292\n",
      "Epoch [2/3], Step [4700/6471], Loss: 2.0350, Perplexity: 7.65191\n",
      "Epoch [2/3], Step [4800/6471], Loss: 2.0022, Perplexity: 7.40555\n",
      "Epoch [2/3], Step [4900/6471], Loss: 2.2182, Perplexity: 9.19120\n",
      "Epoch [2/3], Step [5000/6471], Loss: 2.7470, Perplexity: 15.5956\n",
      "Epoch [2/3], Step [5100/6471], Loss: 2.0418, Perplexity: 7.70487\n",
      "Epoch [2/3], Step [5200/6471], Loss: 2.2714, Perplexity: 9.69259\n",
      "Epoch [2/3], Step [5300/6471], Loss: 1.7809, Perplexity: 5.93537\n",
      "Epoch [2/3], Step [5400/6471], Loss: 2.0633, Perplexity: 7.87199\n",
      "Epoch [2/3], Step [5500/6471], Loss: 2.0751, Perplexity: 7.96559\n",
      "Epoch [2/3], Step [5600/6471], Loss: 1.7529, Perplexity: 5.77159\n",
      "Epoch [2/3], Step [5700/6471], Loss: 1.9245, Perplexity: 6.85181\n",
      "Epoch [2/3], Step [5800/6471], Loss: 2.0681, Perplexity: 7.90954\n",
      "Epoch [2/3], Step [5900/6471], Loss: 1.8168, Perplexity: 6.15193\n",
      "Epoch [2/3], Step [6000/6471], Loss: 1.9927, Perplexity: 7.33519\n",
      "Epoch [2/3], Step [6100/6471], Loss: 1.8218, Perplexity: 6.18285\n",
      "Epoch [2/3], Step [6200/6471], Loss: 1.7822, Perplexity: 5.94304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Step [6300/6471], Loss: 1.9886, Perplexity: 7.30506\n",
      "Epoch [2/3], Step [6400/6471], Loss: 2.1982, Perplexity: 9.00919\n",
      "Epoch [3/3], Step [100/6471], Loss: 1.9390, Perplexity: 6.95217\n",
      "Epoch [3/3], Step [200/6471], Loss: 2.1446, Perplexity: 8.53854\n",
      "Epoch [3/3], Step [300/6471], Loss: 2.1263, Perplexity: 8.38359\n",
      "Epoch [3/3], Step [400/6471], Loss: 2.0456, Perplexity: 7.73414\n",
      "Epoch [3/3], Step [500/6471], Loss: 1.9542, Perplexity: 7.05840\n",
      "Epoch [3/3], Step [600/6471], Loss: 1.9272, Perplexity: 6.87050\n",
      "Epoch [3/3], Step [700/6471], Loss: 1.6981, Perplexity: 5.46379\n",
      "Epoch [3/3], Step [800/6471], Loss: 2.1693, Perplexity: 8.75245\n",
      "Epoch [3/3], Step [900/6471], Loss: 2.3635, Perplexity: 10.6286\n",
      "Epoch [3/3], Step [1000/6471], Loss: 1.8900, Perplexity: 6.6194\n",
      "Epoch [3/3], Step [1100/6471], Loss: 1.9905, Perplexity: 7.31945\n",
      "Epoch [3/3], Step [1200/6471], Loss: 1.9248, Perplexity: 6.85378\n",
      "Epoch [3/3], Step [1300/6471], Loss: 1.8062, Perplexity: 6.08724\n",
      "Epoch [3/3], Step [1400/6471], Loss: 2.1303, Perplexity: 8.41734\n",
      "Epoch [3/3], Step [1500/6471], Loss: 1.9740, Perplexity: 7.19936\n",
      "Epoch [3/3], Step [1600/6471], Loss: 1.8588, Perplexity: 6.41584\n",
      "Epoch [3/3], Step [1700/6471], Loss: 2.7941, Perplexity: 16.3473\n",
      "Epoch [3/3], Step [1800/6471], Loss: 1.8899, Perplexity: 6.61878\n",
      "Epoch [3/3], Step [1900/6471], Loss: 1.8054, Perplexity: 6.08262\n",
      "Epoch [3/3], Step [2000/6471], Loss: 1.7409, Perplexity: 5.70238\n",
      "Epoch [3/3], Step [2100/6471], Loss: 1.7758, Perplexity: 5.90533\n",
      "Epoch [3/3], Step [2200/6471], Loss: 1.8026, Perplexity: 6.06540\n",
      "Epoch [3/3], Step [2300/6471], Loss: 1.9235, Perplexity: 6.84508\n",
      "Epoch [3/3], Step [2400/6471], Loss: 1.8414, Perplexity: 6.30534\n",
      "Epoch [3/3], Step [2500/6471], Loss: 2.2286, Perplexity: 9.28666\n",
      "Epoch [3/3], Step [2600/6471], Loss: 1.8318, Perplexity: 6.24545\n",
      "Epoch [3/3], Step [2700/6471], Loss: 1.8490, Perplexity: 6.35356\n",
      "Epoch [3/3], Step [2800/6471], Loss: 1.7889, Perplexity: 5.98318\n",
      "Epoch [3/3], Step [2900/6471], Loss: 2.0895, Perplexity: 8.08076\n",
      "Epoch [3/3], Step [3000/6471], Loss: 2.1037, Perplexity: 8.19627\n",
      "Epoch [3/3], Step [3100/6471], Loss: 1.9987, Perplexity: 7.37931\n",
      "Epoch [3/3], Step [3200/6471], Loss: 1.9611, Perplexity: 7.107390\n",
      "Epoch [3/3], Step [3300/6471], Loss: 2.1616, Perplexity: 8.68491\n",
      "Epoch [3/3], Step [3400/6471], Loss: 1.9865, Perplexity: 7.28998\n",
      "Epoch [3/3], Step [3500/6471], Loss: 1.8035, Perplexity: 6.07068\n",
      "Epoch [3/3], Step [3600/6471], Loss: 2.1271, Perplexity: 8.39019\n",
      "Epoch [3/3], Step [3700/6471], Loss: 2.0383, Perplexity: 7.67748\n",
      "Epoch [3/3], Step [3800/6471], Loss: 1.7378, Perplexity: 5.68492\n",
      "Epoch [3/3], Step [3900/6471], Loss: 1.7352, Perplexity: 5.67015\n",
      "Epoch [3/3], Step [4000/6471], Loss: 2.0811, Perplexity: 8.01321\n",
      "Epoch [3/3], Step [4100/6471], Loss: 1.9766, Perplexity: 7.21798\n",
      "Epoch [3/3], Step [4200/6471], Loss: 1.9840, Perplexity: 7.27166\n",
      "Epoch [3/3], Step [4300/6471], Loss: 1.7450, Perplexity: 5.72602\n",
      "Epoch [3/3], Step [4400/6471], Loss: 1.8112, Perplexity: 6.11798\n",
      "Epoch [3/3], Step [4500/6471], Loss: 1.8907, Perplexity: 6.62390\n",
      "Epoch [3/3], Step [4600/6471], Loss: 1.8710, Perplexity: 6.49494\n",
      "Epoch [3/3], Step [4700/6471], Loss: 2.0121, Perplexity: 7.47876\n",
      "Epoch [3/3], Step [4800/6471], Loss: 1.8919, Perplexity: 6.63208\n",
      "Epoch [3/3], Step [4900/6471], Loss: 1.7916, Perplexity: 5.99926\n",
      "Epoch [3/3], Step [5000/6471], Loss: 1.8504, Perplexity: 6.36237\n",
      "Epoch [3/3], Step [5100/6471], Loss: 1.8285, Perplexity: 6.22475\n",
      "Epoch [3/3], Step [5200/6471], Loss: 1.8652, Perplexity: 6.45695\n",
      "Epoch [3/3], Step [5300/6471], Loss: 1.9036, Perplexity: 6.71037\n",
      "Epoch [3/3], Step [5400/6471], Loss: 1.9334, Perplexity: 6.91302\n",
      "Epoch [3/3], Step [5500/6471], Loss: 1.6791, Perplexity: 5.36070\n",
      "Epoch [3/3], Step [5600/6471], Loss: 1.9074, Perplexity: 6.73576\n",
      "Epoch [3/3], Step [5700/6471], Loss: 1.8340, Perplexity: 6.25865\n",
      "Epoch [3/3], Step [5800/6471], Loss: 1.7647, Perplexity: 5.84009\n",
      "Epoch [3/3], Step [5900/6471], Loss: 2.7317, Perplexity: 15.3594\n",
      "Epoch [3/3], Step [6000/6471], Loss: 1.7874, Perplexity: 5.97427\n",
      "Epoch [3/3], Step [6100/6471], Loss: 1.7705, Perplexity: 5.87372\n",
      "Epoch [3/3], Step [6200/6471], Loss: 1.6886, Perplexity: 5.41174\n",
      "Epoch [3/3], Step [6300/6471], Loss: 1.8210, Perplexity: 6.17824\n",
      "Epoch [3/3], Step [6400/6471], Loss: 2.7711, Perplexity: 15.9758\n",
      "Epoch [3/3], Step [6471/6471], Loss: 2.0331, Perplexity: 7.63776"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
